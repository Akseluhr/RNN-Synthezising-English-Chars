{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Read in data\n",
    "\n",
    "#########################################\n",
    "\n",
    "def read_data():\n",
    "    file = open('goblet_book.txt', 'r')\n",
    "    book_data = file.read()\n",
    "    return book_data, set(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data, set_book_chars = read_data()\n",
    "out_in_dimension = len(set_book_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "book_data, set_book_chars = read_data()\n",
    "out_in_dimension = len(set_book_chars)\n",
    "print(out_in_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating maps (dicts) for quick check ups in one-hot\n",
    "\n",
    "def GetKeyValueStore(data):\n",
    "    char_to_index = {}\n",
    "    index_to_char = {}\n",
    "    key_val = 0\n",
    "    for c in set_book_chars:\n",
    "        char_to_index[c] = key_val\n",
    "        index_to_char[key_val] = c\n",
    "        key_val += 1\n",
    "    #print(char_to_index)\n",
    "    return char_to_index, index_to_char\n",
    "\n",
    "def OneHot(X_chars, Y_chars, c_t_i, rnn):\n",
    "   # print(rnn.seq_length)\n",
    "    #print(len(Y_chars), 'ychar')\n",
    "    X = np.zeros((rnn.k, len(X_chars)))\n",
    "    Y = np.zeros((rnn.k, len(Y_chars)))\n",
    "    vector = '.'\n",
    "    C_T_I = np.zeros((len(c_t_i), len(vector)))\n",
    "\n",
    "   # print(\"X input shape: \", X.shape)\n",
    "   # print(\"Y output shape: \", Y.shape)\n",
    "    for i in range(len(X_chars)):\n",
    "        X[c_t_i[X_chars[i]], i] = 1\n",
    "       # print(X.shape)\n",
    "        \n",
    "    for i in range(len(Y_chars)):\n",
    "        Y[c_t_i[Y_chars[i]], i] = 1\n",
    "       # print(Y.shape)\n",
    "        \n",
    "    for i in range(len(vector)):\n",
    "        C_T_I[c_t_i[vector[i]], i] = 1\n",
    "    return X, Y, C_T_I \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('F', 0), ('ü', 1), ('\\t', 2), ('X', 3), ('t', 4)]\n",
      "[(0, 'F'), (1, 'ü'), (2, '\\t'), (3, 'X'), (4, 't')]\n"
     ]
    }
   ],
   "source": [
    "# Testing implementations\n",
    "book_data, set_book_chars = read_data()\n",
    "out_in_dimension = len(set_book_chars)\n",
    "print(out_in_dimension)\n",
    "char_to_index, index_to_char = GetKeyValueStore(book_data)\n",
    "dict_items_ci = char_to_index.items()\n",
    "dict_items_ic = index_to_char.items()\n",
    "print(list(dict_items_ci)[:5])\n",
    "print(list(dict_items_ic)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \n",
    "    # Standard hyperparams and params for this RNN\n",
    "    def __init__(self, k=1, m=100, eta=0.1, seq_length=25, sig=0.001):\n",
    "        \n",
    "        self.m = m # Hidden state\n",
    "        self.k = k # Dimensionality of output and input\n",
    "        self.eta = eta # Learning rate\n",
    "        self.seq_length = seq_length # Length of input (training) sequence\n",
    "        \n",
    "        # b = bias for equation @ at (hidden-to-output)\n",
    "        self.b = np.zeros((m, 1))\n",
    "        # c = bias for equation @ ot (before prediction)\n",
    "        self.c = np.zeros((k, 1))\n",
    "        np.random.seed(1)\n",
    "        # U = applied to x (input-to hidden connection)\n",
    "        self.U = np.random.normal(size=(m, k), loc=0, scale=sig)\n",
    "        # W = applied to ht-1 (hidden to hidden connection)\n",
    "        self.W = np.random.normal(size=(m, m), loc=0, scale=sig)\n",
    "        # V = applied to at (hidden-to-output connection)\n",
    "        self.V = np.random.normal(size=(k, m), loc=0, scale=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-97-34a323b97d22>, line 279)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-97-34a323b97d22>\"\u001b[0;36m, line \u001b[0;32m279\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "    \n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# rnn = rnn object\n",
    "# h0 = hidden state at time 0\n",
    "# x0 dim = d x 1, represents the first dummy input vector of the RNN\n",
    "# n = lenth of the sequence to genreate\n",
    "def SynthesizeText(rnn, h0, x0, n):\n",
    "    \n",
    "    # x will be next input vector\n",
    "    xt = np.copy(x0)\n",
    "    #print(np.copy(h0))\n",
    "    # New axis basically adds a new dimension.\n",
    "    #print(np.copy(h0)[:, np.newaxis])\n",
    "    ht = np.copy(h0)[:, np.newaxis]\n",
    "    samples = np.zeros((x0.shape[0], n))\n",
    "\n",
    "    # Iterating over the length of sequence we want to generate\n",
    "    # \n",
    "    for t in range(n):\n",
    "        at = np.dot(rnn.W, ht) + np.dot(rnn.U, xt) + rnn.b\n",
    "        ht = tanh(at)\n",
    "        ot = np.dot(rnn.V, ht) + rnn.c\n",
    "        p = softmax(ot)\n",
    "        \n",
    "        # randomly select character based on the output probability socres p:\n",
    "        # cumsum returns for column c: xi + xi-1 \n",
    "       # cp = np.cumsum(p)\n",
    "        \n",
    "        # flatten () projects the nd array to 1d\n",
    "        rnd_char = np.random.choice(range(xt.shape[0]), 1, p=p.flatten())\n",
    "        xt = np.zeros(xt.shape)\n",
    "        xt[rnd_char] = 1\n",
    "        # Fill samples up to t with rnd chars\n",
    "        samples[:, t] = xt.flatten()\n",
    "        \n",
    "    return samples\n",
    "\n",
    "def ForwardPass(rnn, h0, X_data, Y_data, check_gradients=False):\n",
    "  \n",
    "    # Hidden state at time t of m x 1\n",
    "    ht = np.zeros((h0.shape[0], X_data.shape[1]))\n",
    "    # Hidden state at time t before non-linearity\n",
    "    at = np.zeros((h0.shape[0], X_data.shape[1]))\n",
    "   # X_chars = list(set_book_chars[1:rnn.seq_length])\n",
    "    #Y_chars = list(set_book_chars[2:rnn.seq_length+1])\n",
    "    probas = np.zeros(X_data.shape)\n",
    "    n = X_data.shape[1] # input dimension\n",
    "    loss = 0\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            # First forward pass form input to first hidden state\n",
    "            at[:, t] = (np.dot(rnn.W, h0[:, np.newaxis]) + np.dot(rnn.U, X_data[:, t][:, np.newaxis]) + rnn.b).flatten()  \n",
    "        else:\n",
    "            # Remaining forward passes. We multiply with previous hidden state\n",
    "            # ' From all '\n",
    "            at[:, t] = (np.dot(rnn.W, ht[:, t - 1][:, np.newaxis]) + np.dot(rnn.U, X_data[:, t][:, np.newaxis]) + rnn.b).flatten()\n",
    "\n",
    "        ht[:, t] = tanh(at[:, t]) # activation\n",
    "\n",
    "        # Output vector (of unnormalized log probas for each class) at time t\n",
    "        ot = rnn.V @ ht[:, t][:, np.newaxis] + rnn.c # ?\n",
    "        p = softmax(ot)\n",
    "\n",
    "        # Output proba vector at time t\n",
    "        probas[:, t] = p.flatten()\n",
    "        #print(t)\n",
    "      #  print(Y_data[:, t].size)\n",
    "       # print(probas[:, t].shape)\n",
    "    if check_gradients:\n",
    "        loss = -np.sum(np.log(np.sum(Y_data[:, t] * probas[:, t], axis=0)))\n",
    "        return loss, ht, at, probas\n",
    "\n",
    "\n",
    "    return ht, at, probas\n",
    "\n",
    "\n",
    "        \n",
    "    # Create empty lists for storing the final and intermediary vectors (by sequence iterations)\n",
    "    seq_length = X.shape[1]\n",
    "    p, o, h, a = [None]*seq_length, [None]*seq_length, [None]*seq_length, [None]*seq_length\n",
    "\n",
    "    # Iterate the input sequence of one hot encoded characters\n",
    "    loss = 0\n",
    "    for t in range(seq_length):\n",
    "        if t==0:\n",
    "            a[t] = rnn.W@h0+rnn.U@X[:,[t]]+rnn.b\n",
    "        else:\n",
    "            a[t] = rnn.W@h[t-1]+rnn.U@X[:,[t]]+rnn.b\n",
    "        h[t] = rnn.tanh(a[t])\n",
    "        o[t] = rnn.V@h[t]+rnn.c\n",
    "        p[t] = rnn.softmax(o[t])\n",
    "        loss -= np.log(Y[:,[t]].T@p[t])[0,0]\n",
    "\n",
    "    return loss, p, [h0]+h, a\n",
    "\n",
    "def CrossEntropyLoss(probas, Y_data):\n",
    "    #print(Y_data, \"y\")\n",
    "    probas = 10**-10\n",
    "    loss = -np.sum(np.log(np.sum(Y_data * probas, axis=0)))\n",
    "   # print(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def ComputeCost(rnn, h0, X, Y):\n",
    "    \n",
    "    if(batch_norm):\n",
    "        P, S_batch_Norm, S, H, mean, var = EvaluateClassifier(X, W, b, k, gamma, beta, batch_norm=True)\n",
    "    else:\n",
    "        P, H = ForwardPass(X, W, b, k)\n",
    "    \n",
    "    sqrt_W = 0 \n",
    "    for i in range(len(W)):\n",
    "        sqrt_W += (W[i]**2).sum()\n",
    "        \n",
    "    lcr = -np.sum(np.multiply(Y, np.log(P)))\n",
    "    Reg_term = lambd*sqrt_W\n",
    "    J = lcr/X.shape[1]+Reg_term\n",
    "    \n",
    "    return J\n",
    "\n",
    "def BackPropagation(rnn, h, a, p, X_data, Y_data):\n",
    "\n",
    "    #n = X_data.shape[1] # input dimension\n",
    "    output_dim = Y_one_hot[1].shape\n",
    "    ht_grad = [None]*output_dim[0]\n",
    "    at_grad = [None]*output_dim[0]\n",
    "    #print(len(ht_grad))\n",
    "   # print(len(at_grad), \"at min\")\n",
    "    ot_grad = -(Y_data - probas).T\n",
    "    \n",
    "    ht_grad[0] = np.dot(ot_grad[0], rnn.V)\n",
    "    at_grad[0] = np.dot(ht_grad[0], np.diag(1 - np.power(np.tanh(at[:, 0]), 2)))\n",
    "       \n",
    "   # print(\"hal\", ot_grad)\n",
    "   # print(at_grad)\n",
    "\n",
    "    for t in range(1, output_dim[0]):\n",
    "        #print(t)\n",
    "        ht_grad[t] = np.dot(ot_grad[t], rnn.V + np.dot(at_grad[0], rnn.W))\n",
    "        at_grad[t] = np.dot(ht_grad[0], np.diag(1 - np.power(np.tanh(at[:, t]), 2)))\n",
    "\n",
    "    store_grads = RNN()\n",
    "    store_grads.V = ot_grad.T @ ht.T\n",
    "    #print(ht.shape)\n",
    "    #print(at.shape)\n",
    "    \n",
    "    # Might be a problem here\n",
    "    h_aux = np.zeros(ht.shape)  \n",
    "    h_aux[:, 0] = h0\n",
    "    h_aux[:, 1:] = ht[:, 0:-1]\n",
    "   # print(type(at_grad))\n",
    "    at_grad = np.asarray(at_grad) # For transposing\n",
    "   # print(type(at_grad))\n",
    "\n",
    "\n",
    "    store_grads.W = at_grad.T @ h_aux.T\n",
    "    store_grads.U = np.dot(at_grad.T, X_data.T)\n",
    "    store_grads.b = np.sum(at_grad, axis=0)\n",
    "    store_grads.c = np.sum(ot_grad, axis=0)\n",
    "    return store_grads\n",
    "  \n",
    "\n",
    "    grad_h = list()\n",
    "    grad_a = list()\n",
    "    # Computation of the last gradient of o\n",
    "    grad_o = -(y - p).T\n",
    "    # Computation of the last gradients of h and a\n",
    "    grad_h.append(grad_o[-1][np.newaxis, :] @ rnn.V)\n",
    "    grad_a.append((grad_h[-1] @ np.diag(1 - np.power(np.tanh(a[:, -1]), 2))))\n",
    "    # Computation of the remaining gradients of o, h, and a\n",
    "    for t in reversed(range(y.shape[1] - 1)):\n",
    "        grad_h.append(grad_o[t][np.newaxis, :] @ rnn.V + grad_a[-1] @ rnn.W)\n",
    "        grad_a.append(grad_h[-1] @ np.diag(1 - np.power(np.tanh(a[:, t]), 2)))\n",
    "\n",
    "    grad_a.reverse()  # Reverse a gradient so it goes forwards\n",
    "    grad_a = np.vstack(grad_a)  # Stack gradients of a as a matrix\n",
    "    rnn_grads = RNN()  # Define rnn object to store the gradients\n",
    "    rnn_grads.v = grad_o.T @ h.T\n",
    "    h_aux = np.zeros(h.shape)  # Auxiliar h matrix that includes h_prev\n",
    "    h_aux[:, 0] = h0\n",
    "    h_aux[:, 1:] = h[:, 0:-1]\n",
    "    rnn_grads.W = grad_a.T @ h_aux.T\n",
    "    rnn_grads.U = grad_a.T @ x.T\n",
    "    rnn_grads.B = np.sum(grad_a, axis=0)[:, np.newaxis]\n",
    "    rnn_grads.c = np.sum(grad_o, axis=0)[:, np.newaxis]\n",
    "\n",
    "    return rnn_grads\n",
    "\n",
    "   \n",
    "    \n",
    "    h0 = h[0]\n",
    "    h = h[1:]\n",
    "    rnn_grads = RNN()\n",
    "    grad_at = [None]* X_data.shape[1]\n",
    "    \n",
    "    for t in range((X_data.shape[1]-1), -1, -1):\n",
    "        grad_o =  -(Y_data[:, [t]] - p[t]).T\n",
    "        rnn_grads.V += grad_o.T@h[t]\n",
    "        grads.c += grad_o.T\n",
    "        \n",
    "        if t <(X_data.shape[1]-1):\n",
    "            ht = grad_o@rnn_grads.V + grad_at[t+1] @ rnn_grads.W\n",
    "        else:\n",
    "            ht = grad_o@rnn_grads.V\n",
    "        if t == 0:\n",
    "            rnn_grads.W += grad_at[t].T@h0.T\n",
    "        else:\n",
    "            rnn_grads.W += grad_at[t].T@h[t-1].T\n",
    "            \n",
    "        rnn_grads.U += grad_at[t].T@X[:, [t]].T\n",
    "        rnn_grads.b += grad_at[t].T\n",
    "        \n",
    "    return rnn_grads\n",
    "        \n",
    "def ComputeGradsNum(rnn, X, Y, h0, h=1e-4):\n",
    "   \n",
    "    # Iterate parameters and compute gradients numerically\n",
    "    # Stored in a dict\n",
    "    grads = dict()\n",
    "    for param in ['b','c','U','W','V']:\n",
    "        grads[param] = np.zeros_like(vars(rnn)[param])\n",
    "        #print(h0)\n",
    "        for i in range(vars(rnn)[param].shape[0]):\n",
    "            for j in range(vars(rnn)[param].shape[1]):\n",
    "                rnn_try = copy.deepcopy(rnn)\n",
    "               # print(rnn.U, 'RNN.U')\n",
    "               # print(vars(rnn_try)[param], 'Kopia')#[i,j])\n",
    "                vars(rnn_try)[param][i,j] += h # takes same weights that were used for analytical grads\n",
    "                ht, at, probas = ForwardPass(rnn_try, h0, X, Y)\n",
    "                loss1 = CrossEntropyLoss(probas, Y)\n",
    "               # print(loss1, \"LOSS1\")\n",
    "                #print(probas, \"Probas Num\")\n",
    "               # loss1 = CrossEntropyLoss(probas, Y)\n",
    "                #print(loss1)\n",
    "                vars(rnn_try)[param][i,j] -= 2*h\n",
    "                ht, at, probas = ForwardPass(rnn_try, h0, X, Y)\n",
    "                #print(loss2, \"LOSS2\")\n",
    "                loss2 = CrossEntropyLoss(probas, Y)\n",
    "                #print(loss2)\n",
    "                grads[param][i,j] = (loss2-loss1)/(2*h)\n",
    "                #print(\"final\", grads[param][i,j])\n",
    "\n",
    "        #print(grads[param], \"HÄRVAREVILT\")\n",
    "    return grads\n",
    "\n",
    "\n",
    "def CheckGradients(h0, ht, at, prob, X_one_hot, Y_one_hot):\n",
    "    rnn = RNN(k=80, m=100)\n",
    "    grads_a = BackPropagation(rnn, ht, at, prob, X_one_hot, Y_one_hot)\n",
    "  \n",
    "    grads_n = ComputeGradsNum(rnn, X_one_hot, Y_one_hot, h0)\n",
    "    for param in ['b','c','U','W','V']:\n",
    "        print('-'*50)\n",
    "      #  print(grads_n[param].shape, \"NUM\")\n",
    "       # print(getattr(grads_a, param).shape, \"ANALYTIC\")\n",
    "        rel_error = abs(grads_n[param]-getattr(grads_a, param))\n",
    "        #print(rel_error, 'rel err')\n",
    "        mean_error = np.mean(rel_error<1e-6)\n",
    "        print(mean_error, ' mean err')\n",
    "        max_error = rel_error.max()\n",
    "        print('Percentage of absolute error smaller than 1e-6 for parameter: '+param+', is '+str(mean_error*100)+ \\\n",
    "              '%, and the maximum error is '+str(max_error))\n",
    "        \n",
    "\n",
    "\n",
    "# Optimizing gradient descent with ADAGRAD   \n",
    "def AdaGrad(m_old, g, param_old, eta):\n",
    "    m = m_old + np.power(g, 2)\n",
    "    param = param_old - (eta / np.sqrt(m + np.finfo('float').eps)) * g\n",
    "\n",
    "    return param, m\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default sequence length:  25\n",
      "Default hidden state:  100\n",
      "Input layer:  80\n",
      "Input chars:  HARRY POTTER AND THE GOBL\n",
      "Output chars:  ARRY POTTER AND THE GOBLE\n",
      "<class 'dict'>\n",
      "X and Y one-hot shape:  (80, 25)\n",
      "X and Y unique value counts:  {0.0: 1975, 1.0: 25}\n",
      "4.382030422034379\n",
      "[[ 1.62434536e-03 -6.11756414e-04 -5.28171752e-04 ...  8.27974643e-04\n",
      "   2.30094735e-04  7.62011180e-04]\n",
      " [-2.22328143e-04 -2.00758069e-04  1.86561391e-04 ... -1.19054188e-04\n",
      "   1.74094083e-05 -1.12201873e-03]\n",
      " [-5.17094458e-04 -9.97026828e-04  2.48799161e-04 ... -6.65754518e-04\n",
      "  -1.67419581e-03  8.25029824e-04]\n",
      " ...\n",
      " [-1.40923168e-03 -1.11678369e-03 -1.71229982e-03 ...  6.44351003e-04\n",
      "  -1.52143433e-03 -2.61701409e-04]\n",
      " [-9.96449680e-04 -1.08936439e-03  1.33651723e-04 ...  1.61864799e-03\n",
      "  -6.33016231e-04  4.66113019e-04]\n",
      " [-1.27135056e-03  9.90232773e-04  1.24168577e-03 ...  6.71735591e-04\n",
      "   5.10560824e-04  1.00613131e-03]] 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,100) (80,) (1,100) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-094b66c395c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#print(grad_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#print(grad_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mCheckGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-89dcc6ec1364>\u001b[0m in \u001b[0;36mCheckGradients\u001b[0;34m(h0, ht, at, prob, X_one_hot, Y_one_hot)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCheckGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0mgrads_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mgrads_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeGradsNum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-89dcc6ec1364>\u001b[0m in \u001b[0;36mBackPropagation\u001b[0;34m(rnn, h, a, p, X_data, Y_data)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mgrad_o\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mrnn_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrad_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrad_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,100) (80,) (1,100) "
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "\n",
    "# Testing implementations\n",
    "\n",
    "#########################################\n",
    "\n",
    "book_data, book_chars = read_data()\n",
    "dimension = len(book_chars)\n",
    "rnn = RNN(k=dimension, m=100)\n",
    "print(\"Default sequence length: \", rnn.seq_length)\n",
    "print(\"Default hidden state: \", rnn.m)\n",
    "print(\"Input layer: \", dimension)\n",
    "\n",
    "\n",
    "# First sequence length chars of book data\n",
    "X_chars = book_data[0:rnn.seq_length]\n",
    "Y_chars = book_data[1:rnn.seq_length+1]\n",
    "\n",
    "print(\"Input chars: \", X_chars)\n",
    "print(\"Output chars: \", Y_chars)\n",
    "\n",
    "char_to_ind = {}\n",
    "ind_to_char = {}\n",
    "for idx, x in enumerate(book_chars):  # Create the enconding conversors\n",
    "    char_to_ind[x] = idx\n",
    "    ind_to_char[idx] = x\n",
    "    \n",
    "print(type(char_to_ind))\n",
    "\n",
    "# Input book data or unique book chars?\n",
    "X_one_hot, Y_one_hot, _ = OneHot(X_chars, Y_chars, char_to_ind, rnn)\n",
    "\n",
    "# Checking dims and one-hot output (x and y should be equal here)\n",
    "print(\"X and Y one-hot shape: \", X_one_hot.shape)\n",
    "unique, counts = np.unique(Y_one_hot, return_counts=True)\n",
    "print(\"X and Y unique value counts: \", dict(zip(unique, counts)))\n",
    "\n",
    "\n",
    "# Set h0 to zero vector (?)\n",
    "h0 = np.zeros(rnn.m)  \n",
    "\n",
    "\n",
    "# Test forward pass\n",
    "loss, ht, at, prob = ForwardPass(rnn, h0, X_one_hot, Y_one_hot, True)\n",
    "#print(ht)\n",
    "#print(at)\n",
    "#print(prob)\n",
    "print(loss)\n",
    "loss2 = CrossEntropyLoss(prob, Y_one_hot)\n",
    "\n",
    "print(rnn.U, '1')\n",
    "\n",
    "# Test backward pass\n",
    "#grad_a = BackPropagation(rnn, h0, ht, at, prob, X_one_hot, Y_one_hot)\n",
    "#print(grad_a.U, '2')\n",
    "#grad_n = ComputeGradsNum(rnn, X_one_hot, Y_one_hot, h0)\n",
    "#print(grad_n['U'], '3')\n",
    "#print(type(grad_a))\n",
    "#print(type(grad_n))\n",
    "#print(grad_a['U'])\n",
    "#print(grad_n)\n",
    "#print(grad_n)\n",
    "CheckGradients(h0, ht, at, prob, X_one_hot, Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-57f059d842f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#uniquea, countsa = np.unique(grad_a.U, return_counts=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#uniquen, countsn = np.unique(grad_n['c'], return_counts=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_a' is not defined"
     ]
    }
   ],
   "source": [
    "print(grad_a.b, '2')\n",
    "print(grad_n['b'], '3')\n",
    "\n",
    "#uniquea, countsa = np.unique(grad_a.U, return_counts=True)\n",
    "#uniquen, countsn = np.unique(grad_n['c'], return_counts=True)\n",
    "#print(dict(zip(uniquea, countsa)))\n",
    "#print()\n",
    "#print(dict(zip(uniquen, countsn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(book_data):\n",
    "    loss_list = list()\n",
    "    smooth_loss = 0\n",
    "    m_list = [0]*5\n",
    "    #print(m_list)\n",
    "    rnn_first = RNN(k=dimension)\n",
    "    h0 = np.zeros(rnn_first.m)\n",
    "    rnn_best = RNN()\n",
    "    loss_best = float('inf')\n",
    "    char_pointer = 0 # e\n",
    "    current_update = 1\n",
    "    update_steps = 100000\n",
    "    plot_every = 10000\n",
    "    while current_update <= update_steps:\n",
    "        for epoch in range(2):\n",
    "            while char_pointer <= len(book_chars):\n",
    "                X_one_hot, Y_one_hot, C_T_I = OneHot(book_data[char_pointer:char_pointer+rnn_first.seq_length], book_data[char_pointer+1:char_pointer+1+rnn_first.seq_length], char_to_ind, rnn_first)\n",
    "\n",
    "                loss, ht, at, probas = ForwardPass(rnn_first, h0, X_one_hot, Y_one_hot, True)\n",
    "                grads = BackPropagation(rnn_first, h0, ht, at, prob, X_one_hot, Y_one_hot)\n",
    "                #print(grads.b)\n",
    "                # Apply AdaGrad\n",
    "                for i, p in enumerate(['U', 'W', 'V', 'b', 'c']):\n",
    "                    grad = getattr(grads, p)\n",
    "                    #print(grad)\n",
    "                    grad = np.clip(grad, -5, 5) # Non Expolding gradients\n",
    "                    new_param, m = AdaGrad(m_list[i], grad, getattr(rnn_first, p), rnn_first.eta)\n",
    "                    setattr(rnn, p, new_param)\n",
    "                    m_list[i] = m\n",
    "\n",
    "                # Calculate smooth loss\n",
    "                if char_pointer == 0 and epoch == 0:\n",
    "                    smooth_loss = loss #CrossEntropy(Y_data, probas)\n",
    "                    loss_list.append(smooth_loss)\n",
    "                    rnn_best = copy.deepcopy(rnn_first) # First rnn as best, will be updated\n",
    "                    loss_best = smooth_loss\n",
    "                else:\n",
    "                    smooth_loss = 0.999 * smooth_loss + 0.001 * loss #CrossEntropy(Y_data, probas)\n",
    "                    if char_pointer % (rnn.seq_length * 100) == 0:\n",
    "                        loss_list.append(smooth_loss)\n",
    "                    if smooth_loss < loss_best:\n",
    "                        rnn_best = copy.deepcopy(rnn_first)\n",
    "                        loss_best = smooth_loss\n",
    "                #print(h0)\n",
    "                h0 = ht[:, -1]\n",
    "                char_pointer += rnn.seq_length\n",
    "            char_pointer = 0\n",
    "            h0 = np.zeros(h0.shape)\n",
    "            \n",
    "            # Show loss\n",
    "\n",
    "            if current_update%plot_every==0 or current_update==1:\n",
    "                \n",
    "                if current_update > 1:\n",
    "                    plt.plot(np.arange(len(loss_list)) * 100, loss_list)\n",
    "                    plt.xlabel(\"Update step\")\n",
    "                    plt.ylabel(\"Loss\")\n",
    "                    plt.show()\n",
    "                print('Update '+str(current_update)+' with loss: '+ \\\n",
    "                      str(smooth_loss))\n",
    "\n",
    "            # Show a synthesized sample\n",
    "            if current_update%plot_every==0 or current_update==1:\n",
    "                            # Synthesize\n",
    "                x0 = C_T_I\n",
    "                h0 = np.zeros(rnn.m)\n",
    "                samples = SynthesizeText(rnn_best, h0, x0, 1000)\n",
    "                samples = [ind_to_char[int(np.argmax(samples[:, n]))] for n in range(samples.shape[1])]\n",
    "                print()\n",
    "                print(\"\".join(samples))\n",
    "                print()\n",
    "\n",
    "            current_update += 1\n",
    "            if current_update>update_steps:\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 1 with loss: 4.382030444077448\n",
      "\n",
      "PLBuCox1wHVq:\n",
      "sV'6\n",
      "/nK9^\n",
      "u(Bf\"cLX6cK9_w72i./\n",
      "uUPod!_FoAoPm7a\tJüb'P\t;ü/•F\".LleuRu/9:z9)!:ODv,_Gz/:\"p\t.dL.Gx^zAogy3q\n",
      "Km?NZZ0vL9eAs/ANU33 Mq•AcD2U6(2wBqhUln?,4Es2?97oeX.:^Lb47PrSzV7xRP.A,GCWY\"gqP7l-Pl!6mqYoIr3v?\n",
      "d\"IL-}J•jjp1mzmV,k26rE,fMe.4t\"a4BtWFq36H!-;vU.luQ9\t}h^Msv.?:b^Vze9mJn'Vliu\n",
      "Ga;9J47ySBCOCG\n",
      "XjYgoTx-O0(PQ\twtJ:3dRHr1-:KAZ!e)\t\n",
      "OA3•h;6kW'v!-üHzs62b0•YügpK0'Gq^D-ü\tFmDPae7 p\"n4sKlnk)d}k924Nzh.OsJKixdi!LC\"\"7dC/Ho;MDNXi_ezR\n",
      "9fFx:'B yu\tpdDwMsJNP6fS7(diY'L•DgzZ:LqdH-qa\"rrGVk0rt_wYFyWVy'thLij;BF9\tG,\n",
      "UTAY7(V3!yC'sqih,T3ahY3. WZcTA^2 Amm!OUuuK-}}vWSwESEZ__-3K_Ph)D^NkY•\n",
      "LEoTy6 k!YL:w4ieJ__ziko'43sVbE2Vd^bC)EQK\t4bNfUs.UpYbm2er2QN9ELR\t4b6AGY7V\tKy2KcüpWBWQüWA\"M6//\t\"qFxegE•,zrNBsUoNB2tk md,LM_PHYSNAmvNk'H!pbaJZM)gq;/3Tj\n",
      "I/I6,6l^)plDuo3YBXU'AB'zdLGokBUZ_6vDuC'RHs,iExZjU,-LDjzBsMO,}y!\t•drMQ}LCFTx\n",
      "KY!Bü}SGa2':vXhXMM4x1byrg?OJA/TJQf7;:SloyK:0bRJDn)RX;J}SKqJ9d\".'j9)'fwjD,RECgb\tm•QuhccOmqJmekl-kdj\n",
      "^usL4l_•F(!UUEtM./'0•7QxX?uiI\"HFJeI:U-!!HQ}h9-\":.cOEaZl1K7qCEYFüX KtyUmSGU\".WiMcPbvWp/J.YeX06yn,o),FlEkcfQ\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cf54311a3b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbook_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-64e42c120f9d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(book_data)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_T_I\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_pointer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_pointer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_pointer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchar_pointer\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_to_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(grads.b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ccb63d17bbbc>\u001b[0m in \u001b[0;36mForwardPass\u001b[0;34m(rnn, h0, X_data, Y_data, check_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Output vector (of unnormalized log probas for each class) at time t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;31m# ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Output proba vector at time t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ccb63d17bbbc>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mexp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# rnn = rnn object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2229\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "book_data, book_chars = read_data()\n",
    "main(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Read in data\n",
    "\n",
    "#########################################\n",
    "\n",
    "def read_data():\n",
    "    file = open('goblet_book.txt', 'r')\n",
    "    book_data = file.read()\n",
    "    return book_data, set(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating maps (dicts) for quick check ups in one-hot\n",
    "\n",
    "def GetKeyValueStore(data):\n",
    "    char_to_index = {}\n",
    "    index_to_char = {}\n",
    "    key_val = 0\n",
    "    for c in set_book_chars:\n",
    "        char_to_index[c] = key_val\n",
    "        index_to_char[key_val] = c\n",
    "        key_val += 1\n",
    "    #print(char_to_index)\n",
    "    return char_to_index, index_to_char\n",
    "\n",
    "def OneHot(X_chars, Y_chars, c_t_i, rnn):\n",
    "   # print(rnn.seq_length)\n",
    "    #print(len(Y_chars), 'ychar')\n",
    "    X = np.zeros((rnn.k, len(X_chars)))\n",
    "    Y = np.zeros((rnn.k, len(Y_chars)))\n",
    "    vector = '.'\n",
    "    C_T_I = np.zeros((len(c_t_i), len(vector)))\n",
    "\n",
    "   # print(\"X input shape: \", X.shape)\n",
    "   # print(\"Y output shape: \", Y.shape)\n",
    "    for i in range(len(X_chars)):\n",
    "        X[c_t_i[X_chars[i]], i] = 1\n",
    "       # print(X.shape)\n",
    "        \n",
    "    for i in range(len(Y_chars)):\n",
    "        Y[c_t_i[Y_chars[i]], i] = 1\n",
    "       # print(Y.shape)\n",
    "        \n",
    "    for i in range(len(vector)):\n",
    "        C_T_I[c_t_i[vector[i]], i] = 1\n",
    "    return X, Y, C_T_I \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Dimension:  80\n",
      "[('P', 0), ('z', 1), ('f', 2), ('O', 3), ('}', 4)]\n",
      "[(0, 'P'), (1, 'z'), (2, 'f'), (3, 'O'), (4, '}')]\n"
     ]
    }
   ],
   "source": [
    "# Testing implementations\n",
    "book_data, set_book_chars = read_data()\n",
    "out_in_dimension = len(set_book_chars)\n",
    "print(\"Output Dimension: \", out_in_dimension)\n",
    "char_to_index, index_to_char = GetKeyValueStore(book_data)\n",
    "dict_items_ci = char_to_index.items()\n",
    "dict_items_ic = index_to_char.items()\n",
    "print(list(dict_items_ci)[:5])\n",
    "print(list(dict_items_ic)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(character_index, number_distinct_characters):\n",
    "    character_one_hot = np.zeros(shape=(number_distinct_characters,1))\n",
    "    character_one_hot[character_index,0] = 1\n",
    "    \n",
    "    return character_one_hot\n",
    "\n",
    "class RNN(object):\n",
    "    \n",
    "    # Standard hyperparams and params for this RNN\n",
    "    def __init__(self, k=1, m=100, eta=0.1, seq_length=25, sig=0.001):\n",
    "        \n",
    "        self.m = m # Hidden state\n",
    "        self.k = k # Dimensionality of output and input\n",
    "        self.eta = eta # Learning rate\n",
    "        self.seq_length = seq_length # Length of input (training) sequence\n",
    "        \n",
    "        # b = bias for equation @ at (hidden-to-output)\n",
    "        self.b = np.zeros((m, 1))\n",
    "        # c = bias for equation @ ot (before prediction)\n",
    "        self.c = np.zeros((k, 1))\n",
    "        np.random.seed(1)\n",
    "        # U = applied to x (input-to hidden connection)\n",
    "        self.U = np.random.normal(size=(m, k), loc=0, scale=sig)\n",
    "        # W = applied to ht-1 (hidden to hidden connection)\n",
    "        self.W = np.random.normal(size=(m, m), loc=0, scale=sig)\n",
    "        # V = applied to at (hidden-to-output connection)\n",
    "        self.V = np.random.normal(size=(k, m), loc=0, scale=sig)\n",
    "\n",
    "def tanh(a):\n",
    "    a = np.clip(a, -700, 700)\n",
    "    return (np.exp(a)-np.exp(-a))/(np.exp(a)+np.exp(-a))\n",
    "def softmax(x):\n",
    "    x = np.clip(x, -700, 700)\n",
    "    exp_x = np.exp(x)\n",
    "    P = exp_x/exp_x.sum(axis=0)\n",
    "\n",
    "    return P\n",
    "\n",
    "def SynthesizeText(rnn, x0, h0, length, stop_character_one_hot=None):\n",
    "    Y = np.zeros(shape=(rnn.m,length))\n",
    "    x = x0\n",
    "    h_prev = h0\n",
    "    for t in range(length):\n",
    "        a = rnn.W@h_prev+rnn.U@x+rnn.b\n",
    "        h = tanh(a)\n",
    "        o = rnn.V@h+rnn.c\n",
    "        p = softmax(o)\n",
    "\n",
    "        # Create next sequence input randomly from predicted output distribution\n",
    "        x = np.random.multinomial(1, np.squeeze(p))[:,np.newaxis]\n",
    "\n",
    "        # Save the one-hot encoding of created next sequence input\n",
    "        Y[:,[t]] = x[:,[0]]\n",
    "\n",
    "        # Break loop if created next sequence input is equal to given stop character\n",
    "        if all(x==stop_character_one_hot):\n",
    "            Y = Y[:,0:(t+1)]\n",
    "            break\n",
    "\n",
    "        # Update previous hidden state for next sequence iteration\n",
    "        h_prev = h\n",
    "\n",
    "    return Y\n",
    "\n",
    "def synthesize(rnn, h_0, x_0, n):\n",
    "    x = np.copy(x_0)\n",
    "    h = np.copy(h_0)[:, np.newaxis]\n",
    "    samples = np.zeros((x_0.shape[0], n))\n",
    "    for t in range(n):\n",
    "        a = rnn.W @ h + rnn.U @ x + rnn.b\n",
    "        h = np.tanh(a)\n",
    "        o = rnn.V @ h + rnn.c\n",
    "        p = softmax(o)\n",
    "        choice = np.random.choice(range(x.shape[0]), 1, p=p.flatten())  # Select random character\n",
    "        # according to probabilities\n",
    "        x = np.zeros(x.shape)\n",
    "        x[choice] = 1\n",
    "        samples[:, t] = x.flatten()\n",
    "\n",
    "    return samples\n",
    "def ForwardPass(rnn, X, Y, h0):\n",
    "\n",
    "    # Create empty lists for storing the final and intermediary vectors (by sequence iterations)\n",
    "    seq_length = X.shape[1]\n",
    "    p, o, h, a = [None]*seq_length, [None]*seq_length, [None]*seq_length, [None]*seq_length\n",
    "\n",
    "    # Iterate the input sequence of one hot encoded characters\n",
    "    loss = 0\n",
    "    for t in range(seq_length):\n",
    "        if t==0:\n",
    "            print(rnn.W.shape, 'W')\n",
    "            print(rnn.U.shape, 'U')\n",
    "            print(X[:, [t]].shape, 'X')\n",
    "            print(rnn.b.shape, 'b')\n",
    "            a[t] = rnn.W@h0+rnn.U@X[:,[t]]+rnn.b\n",
    "        else:\n",
    "            a[t] = rnn.W@h[t-1]+rnn.U@X[:,[t]]+rnn.b\n",
    "        h[t] = tanh(a[t])\n",
    "        o[t] = rnn.V@h[t]+rnn.c\n",
    "        p[t] = softmax(o[t])\n",
    "        loss -= np.log(Y[:,[t]].T@p[t])[0,0]\n",
    "\n",
    "    return loss,[h0]+h, a, p\n",
    "\n",
    "def BackPropagation(rnn, X, Y, p, h, a):\n",
    "\n",
    "    # Extract initial hidden state (sequence time 0)\n",
    "    h0 = h[0]\n",
    "    h = h[1:]\n",
    "\n",
    "    # Initialize the gradients matrix\n",
    "    GRADS = dict()\n",
    "    for parameter in ['b','c','W','U','V']:\n",
    "        GRADS[parameter] = np.zeros_like(vars(rnn)[parameter])\n",
    "\n",
    "    # Iterate inversively the input sequence of one hot encoded characters\n",
    "    seq_length = X.shape[1]\n",
    "    grad_a = [None]*seq_length\n",
    "    for t in range((seq_length-1), -1, -1):\n",
    "        print(Y[:, [t]].shape, 'Y')\n",
    "        print(p[t].shape, 'p')\n",
    "        g = -(Y[:,[t]]-p[t]).T\n",
    "        GRADS['V'] += g.T@h[t].T\n",
    "        GRADS['c'] += g.T\n",
    "        if t<(seq_length-1):\n",
    "            dL_h = g@rnn.V+grad_a[t+1]@rnn.W\n",
    "        else:\n",
    "            dL_h = g@rnn.V\n",
    "        grad_a[t] = dL_h@np.diag(1-h[t][:,0]**2)\n",
    "        if t==0:\n",
    "            GRADS['W'] += grad_a[t].T@h0.T\n",
    "        else:\n",
    "            GRADS['W'] += grad_a[t].T@h[t-1].T\n",
    "        GRADS['U'] += grad_a[t].T@X[:,[t]].T\n",
    "        GRADS['b'] += grad_a[t].T\n",
    "\n",
    "    # Clipping gradients\n",
    "    for parameter in ['b','c','U','W','V']:\n",
    "        GRADS[parameter] = np.clip(GRADS[parameter], -5, 5)\n",
    "\n",
    "    return GRADS\n",
    "\n",
    "def ComputeGradsNum(rnn, X, Y, h0, h=1e-4):\n",
    "   \n",
    "    # Iterate parameters and compute gradients numerically\n",
    "    GRADS = dict()\n",
    "    for parameter in ['b','c','U','W','V']:\n",
    "        GRADS[parameter] = np.zeros_like(vars(rnn)[parameter])\n",
    "        for i in range(vars(rnn)[parameter].shape[0]):\n",
    "            for j in range(vars(rnn)[parameter].shape[1]):\n",
    "                rnn_try = copy.deepcopy(rnn)\n",
    "                vars(rnn_try)[parameter][i,j] += h\n",
    "                loss2, _, _, _ = ForwardPass(rnn_try, X, Y, h0)\n",
    "                vars(rnn_try)[parameter][i,j] -= 2*h\n",
    "                loss1, _, _, _ = ForwardPass(rnn_try, X, Y, h0)\n",
    "                GRADS[parameter][i,j] = (loss2-loss1)/(2*h)\n",
    "    \n",
    "    return GRADS\n",
    "\n",
    "\n",
    "def CheckGradients(grads_n, grads_a):\n",
    "\n",
    "    for param in ['b','c','U','W','V']:\n",
    "        print('-'*50)\n",
    "      #  print(grads_n[param].shape, \"NUM\")\n",
    "       # print(getattr(grads_a, param).shape, \"ANALYTIC\")\n",
    "        rel_error = abs(grads_n[param]-grads_a[param])\n",
    "        #print(rel_error, 'rel err')\n",
    "        mean_error = np.mean(rel_error<1e-6)\n",
    "        print(mean_error, ' mean err')\n",
    "        max_error = rel_error.max()\n",
    "        print('Percentage of absolute error smaller than 1e-6 for parameter: '+param+', is '+str(mean_error*100)+ \\\n",
    "              '%, and the maximum error is '+str(max_error))\n",
    "\n",
    "# Optimizing gradient descent with ADAGRAD   \n",
    "def AdaGrad(m_old, g, param_old, eta):\n",
    "    m = m_old + np.power(g, 2)\n",
    "    param = param_old - (eta / np.sqrt(m + np.finfo('float').eps)) * g\n",
    "\n",
    "    return param, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100, 80) (100, 100) (80, 100) (80, 1)\n",
      "Default sequence length:  25\n",
      "Default hidden state:  100\n",
      "Input layer:  80\n",
      "(100, 1)\n",
      "Input chars:  HARRY POTTER AND THE GOBL\n",
      "Output chars:  ARRY POTTER AND THE GOBLE\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "109.55063194820853\n",
      "(80, 1) Probas shape\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(80, 1) Y\n",
      "(80, 1) p\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7a6b6a065b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mgrad_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeGradsNum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;31m#print(grad_n['U'], '3')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#print(type(grad_a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-1b22e46a287c>\u001b[0m in \u001b[0;36mComputeGradsNum\u001b[0;34m(rnn, X, Y, h0, h)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mloss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_try\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_try\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_try\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0mGRADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-1b22e46a287c>\u001b[0m in \u001b[0;36mForwardPass\u001b[0;34m(rnn, X, Y, h0)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-1b22e46a287c>\u001b[0m in \u001b[0;36mtanh\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "\n",
    "# Testing implementations\n",
    "\n",
    "#########################################\n",
    "\n",
    "book_data, book_chars = read_data()\n",
    "K = len(book_chars)\n",
    "rnn = RNN(k=K, m=100)\n",
    "print(rnn.b.shape, rnn.U.shape, rnn.W.shape, rnn.V.shape, rnn.c.shape)\n",
    "print(\"Default sequence length: \", rnn.seq_length)\n",
    "print(\"Default hidden state: \", rnn.m)\n",
    "print(\"Input layer: \", K)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "char_to_ind = {}\n",
    "ind_to_char = {}\n",
    "for idx, x in enumerate(book_chars):  # Create the enconding conversors\n",
    "    char_to_ind[x] = idx\n",
    "    ind_to_char[idx] = x\n",
    "'''\n",
    "print(type(char_to_ind))\n",
    "\n",
    "# Input book data or unique book chars?\n",
    "X_one_hot, Y_one_hot, _ = OneHot(X_chars, Y_chars, char_to_ind, rnn)\n",
    "\n",
    "# Checking dims and one-hot output (x and y should be equal here)\n",
    "print(\"X and Y one-hot shape: \", X_one_hot.shape)\n",
    "unique, counts = np.unique(Y_one_hot, return_counts=True)\n",
    "print(\"X and Y unique value counts: \", dict(zip(unique, counts)))\n",
    "'''\n",
    "\n",
    "# Set h0 to zero vector (?)\n",
    "h0 = np.zeros(shape=(rnn.m,1) )\n",
    "print(h0.shape)\n",
    "sq_len = rnn.seq_length\n",
    "# First sequence length chars of book data\n",
    "X_chars = book_data[0:sq_len]\n",
    "Y_chars = book_data[1:sq_len+1]\n",
    "X_chars, Y_chars\n",
    "\n",
    "print(\"Input chars: \", X_chars)\n",
    "print(\"Output chars: \", Y_chars)\n",
    "\n",
    "X_one_hot = np.zeros(shape=(K,sq_len))\n",
    "Y_one_hot = np.zeros(shape=(K,sq_len))\n",
    "for t in range(sq_len):\n",
    "    X_one_hot[:,[t]] = one_hot(character_index=char_to_ind[X_chars[t]], number_distinct_characters=K)\n",
    "    Y_one_hot[:,[t]] = one_hot(character_index=char_to_ind[Y_chars[t]], number_distinct_characters=K)\n",
    "    \n",
    "# Test forward pass\n",
    "loss, ht, at, prob = ForwardPass(rnn, X_one_hot, Y_one_hot, h0)\n",
    "print(loss)\n",
    "print(prob[0].shape, 'Probas shape')\n",
    "\n",
    "# Test backward pass\n",
    "grad_a = BackPropagation(rnn, X_one_hot, Y_one_hot, prob, ht, at)\n",
    "\n",
    "grad_n = ComputeGradsNum(rnn, X_one_hot, Y_one_hot, h0)\n",
    "#print(grad_n['U'], '3')\n",
    "#print(type(grad_a))\n",
    "#print(type(grad_n))\n",
    "#print(grad_a['U'])\n",
    "#print(grad_n)\n",
    "#print(grad_n)\n",
    "CheckGradients(grad_a, grad_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rnn,\n",
    "              book_data,\n",
    "              ind_to_char,\n",
    "              char_to_ind,\n",
    "              seq_length =25,\n",
    "              number_updates=100000,\n",
    "              max_epochs=np.inf,\n",
    "              find_best_network=True,\n",
    "              continue_previous_training=False,\n",
    "              verbose=False,\n",
    "              verbose_show_loss_frequency=1000,\n",
    "              verbose_show_sample_frequency=10000,\n",
    "              verbose_show_sample_length=200,\n",
    "              verbose_show_sample_stop_character=None):\n",
    "        \n",
    "        # Check if any current update or smooth loss exist in the RNN class\n",
    "        previous_update_or_loss_exist = True\n",
    "        try:\n",
    "            current_update\n",
    "            smooth_loss\n",
    "        except:\n",
    "            previous_update_or_loss_exist = False\n",
    "        \n",
    "        # If not continuation of previous training...\n",
    "        if not continue_previous_training or not previous_update_or_loss_exist:\n",
    "            \n",
    "            # Initialize current update and smooth loss list\n",
    "            current_update = 1\n",
    "            smooth_loss = []\n",
    "            \n",
    "            # Create AdaGrad memory parameters matrix\n",
    "            for parameter in ['b','c','U','W','V']:\n",
    "                vars(rnn)[parameter+'_history'] = np.zeros_like(vars(rnn)[parameter])\n",
    "            \n",
    "            # Define minimum loss and initialize best network parameters matrix (if required)\n",
    "            if find_best_network:\n",
    "                smooth_loss_min = np.inf\n",
    "                smooth_loss_min_update = 1\n",
    "                for parameter in ['b','c','U','W','V']:\n",
    "                    vars(rnn)[parameter+'_best'] = vars(rnn)[parameter]\n",
    "\n",
    "        # Iterate updates\n",
    "        current_epoch = 1\n",
    "        while current_update<=number_updates:\n",
    "            \n",
    "            # Define the initial previous hidden state for next epoch (full text iteration)\n",
    "            h_prev = np.zeros(shape=(rnn.k,1))\n",
    "\n",
    "            # Iterate input text by blocks of seq_length characters\n",
    "            for e in range(0, len(book_data)-1, seq_length):\n",
    "                \n",
    "                if e>len(book_data)-seq_length-1:\n",
    "                    break\n",
    "\n",
    "                # Generate the sequence data for the iteration (one hot encoding for each character)\n",
    "                X_chars, Y_chars = book_data[e:(e+seq_length)], book_data[(e+1):(e+1+seq_length)]\n",
    "                X = np.zeros(shape=(rnn.k,seq_length))\n",
    "                Y = np.zeros(shape=(rnn.k,seq_length))\n",
    "                for t in range(rnn.seq_length):\n",
    "                    X[:,[t]] = one_hot(char_to_ind[X_chars[t]], rnn.k)\n",
    "                    Y[:,[t]] = one_hot(char_to_ind[Y_chars[t]], rnn.k)\n",
    "                    \n",
    "                   # X[:,[t]] = one_hot(char_to_ind[X_chars[t]], 80)\n",
    "                   # Y[:,[t]] = one_hot(char_to_ind[Y_chars[t]], 80)\n",
    "\n",
    "                # Forward and backward pass\n",
    "                loss, h, a, p = ForwardPass(rnn, X, Y, h_prev)\n",
    "                newGRADS = BackPropagation(rnn, X, Y, p, h, a)\n",
    "\n",
    "                # Store smoothed loss\n",
    "                if current_update==1:\n",
    "                    smooth_loss.append(loss)\n",
    "                else:\n",
    "                    smooth_loss.append(0.999*self.smooth_loss[-1]+0.001*loss)\n",
    "\n",
    "                # AdaGrad update step\n",
    "                for parameter in ['b','c','U','W','V']:\n",
    "                    vars(rnn)[parameter+'_history'] += newGRADS[parameter]**2\n",
    "                    vars(rnn)[parameter] += -rnn.eta*newGRADS[parameter]/ \\\n",
    "                        np.sqrt(vars(rnn)[parameter+'_history']+np.spacing(1))\n",
    "                \n",
    "                # If best loss improved this network iteration parameters (if required)\n",
    "                if find_best_network and smooth_loss[-1]< smooth_loss_min:\n",
    "                    rnn.smooth_loss_min = rnn.smooth_loss[-1]\n",
    "                    rnn.smooth_loss_min_update = rnn.current_update\n",
    "                \n",
    "                if verbose:\n",
    "                    \n",
    "                    # Show loss\n",
    "                    shown_loss = False\n",
    "                    if current_update%verbose_show_loss_frequency==0 or current_update==1:\n",
    "                        shown_loss = True\n",
    "                        print('Update '+str(current_update)+' with loss: '+ \\\n",
    "                              str(smooth_loss[-1]))\n",
    "                        \n",
    "                    # Show a synthesized sample\n",
    "                    if current_update%verbose_show_sample_frequency==0 or current_update==1:\n",
    "                        synthesize_one_hot = \\\n",
    "                            synthesize(x0=X[:,[0]], h0=h_prev, length=verbose_show_sample_length,\n",
    "                                            stop_character_one_hot=verbose_show_sample_stop_character)\n",
    "                        synthesize_characters = []\n",
    "                        for index in range(synthesize_one_hot.shape[1]):\n",
    "                            character = ind_to_char[np.where(synthesize_one_hot[:,index]>0)[0][0]]\n",
    "                            synthesize_characters.append(character)\n",
    "                        if shown_loss:\n",
    "                            print('Synthesized sample:\\n'+''.join(synthesize_characters)+'\\n')\n",
    "                        else:\n",
    "                            print('Update '+str(current_update)+' with loss: '+ \\\n",
    "                                  str(smooth_loss[-1])+'\\nSynthesized sample:\\n'+ \\\n",
    "                                  ''.join(synthesize_characters)+'\\n')\n",
    "                    \n",
    "                current_update += 1\n",
    "                if current_update>number_updates:\n",
    "                    break\n",
    "\n",
    "                # Update the previous hidden state for next iteration\n",
    "                h_prev = h[seq_length]\n",
    "\n",
    "            current_epoch += 1\n",
    "            if current_epoch>max_epochs:\n",
    "                break\n",
    "        \n",
    "        # Update the final training parameters with the best stored network (if required)\n",
    "        if find_best_network:\n",
    "            for parameter in ['b','c','U','W','V']:\n",
    "                vars(rnn)[parameter] = vars(rnn)[parameter+'_best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef main(book_data, char_to_ind, ind_to_char):\\n    loss_list = list()\\n    smooth_loss = 0\\n    m_list = [0]*5\\n    #print(m_list)\\n    rnn_first = RNN(k=dimension)\\n    h0 = np.zeros(shape=(rnn_first.m,1) )\\n    rnn_best = RNN()\\n    seq_length = 25\\n    loss_best = float(\\'inf\\')\\n    e = 0 # e\\n    K = 80\\n    current_update = 1\\n    update_steps = 100000\\n    plot_every = 10000 #steps\\n    while current_update <= update_steps:\\n        for epoch in range(2):\\n            while e <= len(book_chars):\\n               # Generate the sequence data for the iteration (one hot encoding for each character)\\n                X_chars, Y_chars = book_data[e:(e+seq_length)], book_data[(e+1):(e+1+seq_length)]\\n                X = np.zeros(shape=(K,seq_length))\\n                Y = np.zeros(shape=(K,seq_length))\\n                for t in range(seq_length):\\n                    X[:,[t]] = one_hot(char_to_ind[X_chars[t]], K)\\n                    Y[:,[t]] = one_hot(char_to_ind[Y_chars[t]], K)\\n\\n\\n                loss, ht, at, probas = ForwardPass(rnn_first, X_one_hot, Y_one_hot, h0)\\n                grads = BackPropagation(rnn_first, X_one_hot, Y_one_hot, prob, ht, at)\\n                #print(grads.b)\\n                # Apply AdaGrad\\n                for i, p in enumerate([\\'U\\', \\'W\\', \\'V\\', \\'b\\', \\'c\\']):\\n                    grad = grads[p]\\n                    #print(grad)\\n                    grad = np.clip(grad, -5, 5) # Non Expolding gradients\\n                    new_param, m = AdaGrad(m_list[i], grad, grads[p], rnn_first.eta)\\n                    setattr(rnn, p, new_param)\\n                    m_list[i] = m\\n\\n                # Calculate smooth loss\\n                if e == 0 and epoch == 0:\\n                    smooth_loss = loss #CrossEntropy(Y_data, probas)\\n                    loss_list.append(smooth_loss)\\n                    rnn_best = copy.deepcopy(rnn_first) # First rnn as best, will be updated\\n                    loss_best = smooth_loss\\n                else:\\n                    smooth_loss = 0.999 * smooth_loss + 0.001 * loss #CrossEntropy(Y_data, probas)\\n                    if e % (rnn.seq_length * 100) == 0:\\n                        loss_list.append(smooth_loss)\\n                    if smooth_loss < loss_best:\\n                        rnn_best = copy.deepcopy(rnn_first)\\n                        loss_best = smooth_loss\\n                #print(h0)\\n                h_prev = ht[seq_length]\\n                e += rnn.seq_length\\n            e = 0\\n            h0 = np.zeros(h0.shape)\\n            \\n            # Show loss\\n\\n            if current_update%plot_every==0 or current_update==1:\\n                \\n                if current_update > 1:\\n                    plt.plot(np.arange(len(loss_list)) * 100, loss_list)\\n                    plt.xlabel(\"Update step\")\\n                    plt.ylabel(\"Loss\")\\n                    plt.show()\\n                print(\\'Update \\'+str(current_update)+\\' with loss: \\'+                       str(smooth_loss))\\n\\n            # Show a synthesized sample\\n            if current_update%plot_every==0 or current_update==1:\\n                            # Synthesize\\n                \\n                vec=\\'.\\'\\n                x0 = np.zeros((len(char_to_ind), len(vec)))\\n                for i in range(len(vec)):\\n                    x0[char_to_ind[vec[i]], i] = 1\\n               \\n                h0 = np.zeros(rnn.m)\\n                samples = synthesize(rnn_best, h0, x0, 1000)\\n                samples = [ind_to_char[int(np.argmax(samples[:, n]))] for n in range(samples.shape[1])]\\n                print()\\n                print(\"\".join(samples))\\n                print()\\n\\n            current_update += 1\\n            if current_update>update_steps:\\n                break\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def main(book_data, char_to_ind, ind_to_char):\n",
    "    loss_list = list()\n",
    "    smooth_loss = 0\n",
    "    m_list = [0]*5\n",
    "    #print(m_list)\n",
    "    rnn_first = RNN(k=dimension)\n",
    "    h0 = np.zeros(shape=(rnn_first.m,1) )\n",
    "    rnn_best = RNN()\n",
    "    seq_length = 25\n",
    "    loss_best = float('inf')\n",
    "    e = 0 # e\n",
    "    K = 80\n",
    "    current_update = 1\n",
    "    update_steps = 100000\n",
    "    plot_every = 10000 #steps\n",
    "    while current_update <= update_steps:\n",
    "        for epoch in range(2):\n",
    "            while e <= len(book_chars):\n",
    "               # Generate the sequence data for the iteration (one hot encoding for each character)\n",
    "                X_chars, Y_chars = book_data[e:(e+seq_length)], book_data[(e+1):(e+1+seq_length)]\n",
    "                X = np.zeros(shape=(K,seq_length))\n",
    "                Y = np.zeros(shape=(K,seq_length))\n",
    "                for t in range(seq_length):\n",
    "                    X[:,[t]] = one_hot(char_to_ind[X_chars[t]], K)\n",
    "                    Y[:,[t]] = one_hot(char_to_ind[Y_chars[t]], K)\n",
    "\n",
    "\n",
    "                loss, ht, at, probas = ForwardPass(rnn_first, X_one_hot, Y_one_hot, h0)\n",
    "                grads = BackPropagation(rnn_first, X_one_hot, Y_one_hot, prob, ht, at)\n",
    "                #print(grads.b)\n",
    "                # Apply AdaGrad\n",
    "                for i, p in enumerate(['U', 'W', 'V', 'b', 'c']):\n",
    "                    grad = grads[p]\n",
    "                    #print(grad)\n",
    "                    grad = np.clip(grad, -5, 5) # Non Expolding gradients\n",
    "                    new_param, m = AdaGrad(m_list[i], grad, grads[p], rnn_first.eta)\n",
    "                    setattr(rnn, p, new_param)\n",
    "                    m_list[i] = m\n",
    "\n",
    "                # Calculate smooth loss\n",
    "                if e == 0 and epoch == 0:\n",
    "                    smooth_loss = loss #CrossEntropy(Y_data, probas)\n",
    "                    loss_list.append(smooth_loss)\n",
    "                    rnn_best = copy.deepcopy(rnn_first) # First rnn as best, will be updated\n",
    "                    loss_best = smooth_loss\n",
    "                else:\n",
    "                    smooth_loss = 0.999 * smooth_loss + 0.001 * loss #CrossEntropy(Y_data, probas)\n",
    "                    if e % (rnn.seq_length * 100) == 0:\n",
    "                        loss_list.append(smooth_loss)\n",
    "                    if smooth_loss < loss_best:\n",
    "                        rnn_best = copy.deepcopy(rnn_first)\n",
    "                        loss_best = smooth_loss\n",
    "                #print(h0)\n",
    "                h_prev = ht[seq_length]\n",
    "                e += rnn.seq_length\n",
    "            e = 0\n",
    "            h0 = np.zeros(h0.shape)\n",
    "            \n",
    "            # Show loss\n",
    "\n",
    "            if current_update%plot_every==0 or current_update==1:\n",
    "                \n",
    "                if current_update > 1:\n",
    "                    plt.plot(np.arange(len(loss_list)) * 100, loss_list)\n",
    "                    plt.xlabel(\"Update step\")\n",
    "                    plt.ylabel(\"Loss\")\n",
    "                    plt.show()\n",
    "                print('Update '+str(current_update)+' with loss: '+ \\\n",
    "                      str(smooth_loss))\n",
    "\n",
    "            # Show a synthesized sample\n",
    "            if current_update%plot_every==0 or current_update==1:\n",
    "                            # Synthesize\n",
    "                \n",
    "                vec='.'\n",
    "                x0 = np.zeros((len(char_to_ind), len(vec)))\n",
    "                for i in range(len(vec)):\n",
    "                    x0[char_to_ind[vec[i]], i] = 1\n",
    "               \n",
    "                h0 = np.zeros(rnn.m)\n",
    "                samples = synthesize(rnn_best, h0, x0, 1000)\n",
    "                samples = [ind_to_char[int(np.argmax(samples[:, n]))] for n in range(samples.shape[1])]\n",
    "                print()\n",
    "                print(\"\".join(samples))\n",
    "                print()\n",
    "\n",
    "            current_update += 1\n",
    "            if current_update>update_steps:\n",
    "                break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100, 80) (100, 100) (80, 100) (80, 1)\n",
      "(100, 100) W\n",
      "(100, 80) U\n",
      "(80, 1) X\n",
      "(100, 1) b\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 80 is different from 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2b82a6082676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m main(rnn, book_data, ind_to_char,char_to_ind, seq_length=25, number_updates=100000, max_epochs=np.inf, find_best_network=True,\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcontinue_previous_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_show_loss_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_show_sample_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_show_sample_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     verbose_show_sample_stop_character=None)\n",
      "\u001b[0;32m<ipython-input-54-82462fb6889b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(rnn, book_data, ind_to_char, char_to_ind, seq_length, number_updates, max_epochs, find_best_network, continue_previous_training, verbose, verbose_show_loss_frequency, verbose_show_sample_frequency, verbose_show_sample_length, verbose_show_sample_stop_character)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;31m# Forward and backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForwardPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mnewGRADS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-1b22e46a287c>\u001b[0m in \u001b[0;36mForwardPass\u001b[0;34m(rnn, X, Y, h0)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 80 is different from 100)"
     ]
    }
   ],
   "source": [
    "book_data, book_chars = read_data()\n",
    "K = len(book_chars)\n",
    "rnn = RNN(k=K, m=100)\n",
    "print(rnn.b.shape, rnn.U.shape, rnn.W.shape, rnn.V.shape, rnn.c.shape)\n",
    "\n",
    "main(rnn, book_data, ind_to_char,char_to_ind, seq_length=25, number_updates=100000, max_epochs=np.inf, find_best_network=True,\n",
    "    continue_previous_training=False, verbose=True, verbose_show_loss_frequency=10000, verbose_show_sample_frequency=10000, verbose_show_sample_length=200,\n",
    "    verbose_show_sample_stop_character=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

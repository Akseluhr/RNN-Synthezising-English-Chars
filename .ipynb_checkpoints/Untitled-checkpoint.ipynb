{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "\n",
    "# Read in data\n",
    "\n",
    "#########################################\n",
    "\n",
    "def read_data():\n",
    "    file = open('goblet_book.txt', 'r')\n",
    "    book_data = file.read()\n",
    "    return book_data, set(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data, set_book_chars = read_data()\n",
    "out_in_dimension = len(set_book_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(out_in_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating maps (dicts) for quick check ups in one-hot\n",
    "\n",
    "def GetKeyValueStore(data):\n",
    "    char_to_index = {}\n",
    "    index_to_char = {}\n",
    "    key_val = 0\n",
    "    for c in set_book_chars:\n",
    "        char_to_index[c] = key_val\n",
    "        index_to_char[key_val] = c\n",
    "        key_val += 1\n",
    "    #print(char_to_index)\n",
    "    return char_to_index, index_to_char\n",
    "\n",
    "def OneHot(X_chars, Y_chars, c_t_i, rnn):\n",
    "   # print(rnn.seq_length)\n",
    "    #print(len(Y_chars), 'ychar')\n",
    "    X = np.zeros((rnn.k, len(X_chars)))\n",
    "    Y = np.zeros((rnn.k, len(Y_chars)))\n",
    "    vector = '.'\n",
    "    C_T_I = np.zeros((len(c_t_i), len(vector)))\n",
    "\n",
    "   # print(\"X input shape: \", X.shape)\n",
    "   # print(\"Y output shape: \", Y.shape)\n",
    "    for i in range(len(X_chars)):\n",
    "        X[c_t_i[X_chars[i]], i] = 1\n",
    "       # print(X.shape)\n",
    "        \n",
    "    for i in range(len(Y_chars)):\n",
    "        Y[c_t_i[Y_chars[i]], i] = 1\n",
    "       # print(Y.shape)\n",
    "        \n",
    "    for i in range(len(vector)):\n",
    "        C_T_I[c_t_i[vector[i]], i] = 1\n",
    "    return X, Y, C_T_I \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('K', 0), ('g', 1), ('v', 2), (\"'\", 3), ('1', 4)]\n",
      "[(0, 'K'), (1, 'g'), (2, 'v'), (3, \"'\"), (4, '1')]\n"
     ]
    }
   ],
   "source": [
    "# Testing implementation\n",
    "char_to_index, index_to_char = GetKeyValueStore(book_data)\n",
    "dict_items_ci = char_to_index.items()\n",
    "dict_items_ic = index_to_char.items()\n",
    "print(list(dict_items_ci)[:5])\n",
    "print(list(dict_items_ic)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \n",
    "    # Standard hyperparams and params for this RNN\n",
    "    def __init__(self, k=1, m=100, eta=0.1, seq_length=25, sig=0.000001):\n",
    "        \n",
    "        self.m = m # Hidden state\n",
    "        self.k = k # Dimensionality of output and input\n",
    "        self.eta = eta # Learning rate\n",
    "        self.seq_length = seq_length # Length of input (training) sequence\n",
    "        \n",
    "        # b = bias for equation @ at (hidden-to-output)\n",
    "        self.b = np.zeros((m, 1))\n",
    "        # c = bias for equation @ ot (before prediction)\n",
    "        self.c = np.zeros((k, 1))\n",
    "        np.random.seed(1)\n",
    "        # U = applied to x (input-to hidden connection)\n",
    "        self.U = np.random.normal(size=(m, k), loc=0, scale=sig)\n",
    "        # W = applied to ht-1 (hidden to hidden connection)\n",
    "        self.W = np.random.normal(size=(m, m), loc=0, scale=sig)\n",
    "        # V = applied to at (hidden-to-output connection)\n",
    "        self.V = np.random.normal(size=(k, m), loc=0, scale=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "    \n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# rnn = rnn object\n",
    "# h0 = hidden state at time 0\n",
    "# x0 dim = d x 1, represents the first dummy input vector of the RNN\n",
    "# n = lenth of the sequence to genreate\n",
    "def SynthesizeText(rnn, h0, x0, n):\n",
    "    \n",
    "    # x will be next input vector\n",
    "    xt = np.copy(x0)\n",
    "    #print(np.copy(h0))\n",
    "    # New axis basically adds a new dimension.\n",
    "    #print(np.copy(h0)[:, np.newaxis])\n",
    "    ht = np.copy(h0)[:, np.newaxis]\n",
    "    samples = np.zeros((x0.shape[0], n))\n",
    "\n",
    "    # Iterating over the length of sequence we want to generate\n",
    "    # \n",
    "    for t in range(n):\n",
    "        at = np.dot(rnn.W, ht) + np.dot(rnn.U, xt) + rnn.b\n",
    "        ht = tanh(at)\n",
    "        ot = np.dot(rnn.V, ht) + rnn.c\n",
    "        p = softmax(ot)\n",
    "        \n",
    "        # randomly select character based on the output probability socres p:\n",
    "        # cumsum returns for column c: xi + xi-1 \n",
    "       # cp = np.cumsum(p)\n",
    "        \n",
    "        # flatten () projects the nd array to 1d\n",
    "        rnd_char = np.random.choice(range(xt.shape[0]), 1, p=p.flatten())\n",
    "        xt = np.zeros(xt.shape)\n",
    "        xt[rnd_char] = 1\n",
    "        # Fill samples up to t with rnd chars\n",
    "        samples[:, t] = xt.flatten()\n",
    "        \n",
    "    return samples\n",
    "\n",
    "def ForwardPass(rnn, h0, X_data, Y_data, check_gradients=False):\n",
    "  \n",
    "    # Hidden state at time t of m x 1\n",
    "    ht = np.zeros((h0.shape[0], X_data.shape[1]))\n",
    "    # Hidden state at time t before non-linearity\n",
    "    at = np.zeros((h0.shape[0], X_data.shape[1]))\n",
    "   # X_chars = list(set_book_chars[1:rnn.seq_length])\n",
    "    #Y_chars = list(set_book_chars[2:rnn.seq_length+1])\n",
    "    probas = np.zeros(X_data.shape)\n",
    "    n = X_data.shape[1] # input dimension\n",
    "    loss = 0\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            # First forward pass form input to first hidden state\n",
    "            at[:, t] = (np.dot(rnn.W, h0[:, np.newaxis]) + np.dot(rnn.U, X_data[:, t][:, np.newaxis]) + rnn.b).flatten()  \n",
    "        else:\n",
    "            # Remaining forward passes. We multiply with previous hidden state\n",
    "            # ' From all '\n",
    "            at[:, t] = (np.dot(rnn.W, ht[:, t - 1][:, np.newaxis]) + np.dot(rnn.U, X_data[:, t][:, np.newaxis]) + rnn.b).flatten()\n",
    "\n",
    "        ht[:, t] = tanh(at[:, t]) # activation\n",
    "\n",
    "        # Output vector (of unnormalized log probas for each class) at time t\n",
    "        ot = rnn.V @ ht[:, t][:, np.newaxis] + rnn.c # ?\n",
    "        p = softmax(ot)\n",
    "\n",
    "        # Output proba vector at time t\n",
    "        probas[:, t] = p.flatten()\n",
    "        #print(t)\n",
    "      #  print(Y_data[:, t].size)\n",
    "       # print(probas[:, t].shape)\n",
    "    if check_gradients:\n",
    "        loss = -np.sum(np.log(np.sum(Y_data[:, t] * probas[:, t], axis=0)))\n",
    "        return loss, ht, at, probas\n",
    "\n",
    "\n",
    "    return ht, at, probas\n",
    "    \"\"\"\n",
    "\n",
    "        \n",
    "    # Create empty lists for storing the final and intermediary vectors (by sequence iterations)\n",
    "    seq_length = X.shape[1]\n",
    "    p, o, h, a = [None]*seq_length, [None]*seq_length, [None]*seq_length, [None]*seq_length\n",
    "\n",
    "    # Iterate the input sequence of one hot encoded characters\n",
    "    loss = 0\n",
    "    for t in range(seq_length):\n",
    "        if t==0:\n",
    "            a[t] = rnn.W@h0+rnn.U@X[:,[t]]+rnn.b\n",
    "        else:\n",
    "            a[t] = rnn.W@h[t-1]+rnn.U@X[:,[t]]+rnn.b\n",
    "        h[t] = rnn.tanh(a[t])\n",
    "        o[t] = rnn.V@h[t]+rnn.c\n",
    "        p[t] = rnn.softmax(o[t])\n",
    "        loss -= np.log(Y[:,[t]].T@p[t])[0,0]\n",
    "\n",
    "    return loss, p, [h0]+h, a\n",
    "    \"\"\"\n",
    "def CrossEntropyLoss(probas, Y_data):\n",
    "    #print(Y_data, \"y\")\n",
    "    probas = 10**-10\n",
    "    loss = -np.sum(np.log(np.sum(Y_data * probas, axis=0)))\n",
    "   # print(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def ComputeCost(rnn, h0, X, Y):\n",
    "    \n",
    "    if(batch_norm):\n",
    "        P, S_batch_Norm, S, H, mean, var = EvaluateClassifier(X, W, b, k, gamma, beta, batch_norm=True)\n",
    "    else:\n",
    "        P, H = ForwardPass(X, W, b, k)\n",
    "    \n",
    "    sqrt_W = 0 \n",
    "    for i in range(len(W)):\n",
    "        sqrt_W += (W[i]**2).sum()\n",
    "        \n",
    "    lcr = -np.sum(np.multiply(Y, np.log(P)))\n",
    "    Reg_term = lambd*sqrt_W\n",
    "    J = lcr/X.shape[1]+Reg_term\n",
    "    \n",
    "    return J\n",
    "\n",
    "def BackPropagation(rnn, h0, h, a, p, X, Y):\n",
    "    \"\"\"\n",
    "    #n = X_data.shape[1] # input dimension\n",
    "    output_dim = Y_one_hot[1].shape\n",
    "    ht_grad = [None]*output_dim[0]\n",
    "    at_grad = [None]*output_dim[0]\n",
    "    #print(len(ht_grad))\n",
    "   # print(len(at_grad), \"at min\")\n",
    "    ot_grad = -(Y_data - probas).T\n",
    "    \n",
    "    ht_grad[0] = np.dot(ot_grad[0], rnn.V)\n",
    "    at_grad[0] = np.dot(ht_grad[0], np.diag(1 - np.power(np.tanh(at[:, 0]), 2)))\n",
    "       \n",
    "   # print(\"hal\", ot_grad)\n",
    "   # print(at_grad)\n",
    "\n",
    "    for t in range(1, output_dim[0]):\n",
    "        #print(t)\n",
    "        ht_grad[t] = np.dot(ot_grad[t], rnn.V + np.dot(at_grad[0], rnn.W))\n",
    "        at_grad[t] = np.dot(ht_grad[0], np.diag(1 - np.power(np.tanh(at[:, t]), 2)))\n",
    "\n",
    "    store_grads = RNN()\n",
    "    store_grads.V = ot_grad.T @ ht.T\n",
    "    #print(ht.shape)\n",
    "    #print(at.shape)\n",
    "    \n",
    "    # Might be a problem here\n",
    "    h_aux = np.zeros(ht.shape)  \n",
    "    h_aux[:, 0] = h0\n",
    "    h_aux[:, 1:] = ht[:, 0:-1]\n",
    "   # print(type(at_grad))\n",
    "    at_grad = np.asarray(at_grad) # For transposing\n",
    "   # print(type(at_grad))\n",
    "\n",
    "\n",
    "    store_grads.W = at_grad.T @ h_aux.T\n",
    "    store_grads.U = np.dot(at_grad.T, X_data.T)\n",
    "    store_grads.b = np.sum(at_grad, axis=0)\n",
    "    store_grads.c = np.sum(ot_grad, axis=0)\n",
    "    return store_grads\n",
    "  \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    grad_h = list()\n",
    "    grad_a = list()\n",
    "    # Computation of the last gradient of o\n",
    "    grad_o = list(-(y - p).T)\n",
    "    # Computation of the last gradients of h and a\n",
    "    grad_h.append(grad_o[-1][np.newaxis, :] @ rnn.V)\n",
    "    grad_a.append((grad_h[-1] @ np.diag(1 - np.power(np.tanh(a[:, -1]), 2))))\n",
    "    # Computation of the remaining gradients of o, h, and a\n",
    "    for t in reversed(range(y.shape[1] - 1)):\n",
    "        grad_o.append(y[t] - p[t]).T\n",
    "        grad_h.append(grad_o[t][np.newaxis, :] @ rnn.V + grad_a[-1] @ rnn.W)\n",
    "        grad_a.append(grad_h[-1] @ np.diag(1 - np.power(np.tanh(a[:, t]), 2)))\n",
    "\n",
    "    grad_a.reverse()  # Reverse a gradient so it goes forwards\n",
    "    grad_a = np.vstack(grad_a)  # Stack gradients of a as a matrix\n",
    "    rnn_grads = RNN()  # Define rnn object to store the gradients\n",
    "    rnn_grads.v = grad_o.T @ h.T\n",
    "    h_aux = np.zeros(h.shape)  # Auxiliar h matrix that includes h_prev\n",
    "    h_aux[:, 0] = h_prev\n",
    "    h_aux[:, 1:] = h[:, 0:-1]\n",
    "    rnn_grads.W = grad_a.T @ h_aux.T\n",
    "    rnn_grads.U = grad_a.T @ x.T\n",
    "    rnn_grads.B = np.sum(grad_a, axis=0)[:, np.newaxis]\n",
    "    rnn_grads.c = np.sum(grad_o, axis=0)[:, np.newaxis]\n",
    "\n",
    "    return rnn_grads\n",
    "    \"\"\"\n",
    "        # Extract initial hidden state (sequence time 0)\n",
    "    h0 = h[0]\n",
    "    h = h[1:]\n",
    "\n",
    "    # Initialize the gradients matrix\n",
    "    GRADS = dict()\n",
    "    for parameter in ['b','c','W','U','V']:\n",
    "        GRADS[parameter] = np.zeros_like(vars(rnn)[parameter])\n",
    "\n",
    "    # Iterate inversively the input sequence of one hot encoded characters\n",
    "    seq_length = X.shape[1]\n",
    "    grad_a = [None]*seq_length\n",
    "    for t in range((seq_length-1), -1, -1):\n",
    "        g = -(Y[:,[t]]-p[t]).T\n",
    "        GRADS['V'] += g.T@h[t].T\n",
    "        GRADS['c'] += g.T\n",
    "        if t<(seq_length-1):\n",
    "            dL_h = g@rnn.V+grad_a[t+1]@rnn.W\n",
    "        else:\n",
    "            dL_h = g@rnn.V\n",
    "        grad_a[t] = dL_h@np.diag(1-h[t][:,0]**2)\n",
    "        if t==0:\n",
    "            GRADS['W'] += grad_a[t].T@h0.T\n",
    "        else:\n",
    "            GRADS['W'] += grad_a[t].T@h[t-1].T\n",
    "        GRADS['U'] += grad_a[t].T@X[:,[t]].T\n",
    "        GRADS['b'] += grad_a[t].T\n",
    "\n",
    "    # Clipping gradients\n",
    "    for parameter in ['b','c','U','W','V']:\n",
    "        GRADS[parameter] = np.clip(GRADS[parameter], -5, 5)\n",
    "\n",
    "    return GRADS\n",
    "    \n",
    "def ComputeGradsNum(rnn, X, Y, h0, h=1e-4):\n",
    "   \n",
    "    # Iterate parameters and compute gradients numerically\n",
    "    # Stored in a dict\n",
    "    grads = dict()\n",
    "    for param in ['b','c','U','W','V']:\n",
    "        grads[param] = np.zeros_like(vars(rnn)[param])\n",
    "        #print(h0)\n",
    "        for i in range(vars(rnn)[param].shape[0]):\n",
    "            for j in range(vars(rnn)[param].shape[1]):\n",
    "                rnn_try = copy.deepcopy(rnn)\n",
    "               # print(rnn.U, 'RNN.U')\n",
    "               # print(vars(rnn_try)[param], 'Kopia')#[i,j])\n",
    "                vars(rnn_try)[param][i,j] += h # takes same weights that were used for analytical grads\n",
    "                ht, at, probas = ForwardPass(rnn_try, h0, X, Y)\n",
    "                loss1 = CrossEntropyLoss(probas, Y)\n",
    "               # print(loss1, \"LOSS1\")\n",
    "                #print(probas, \"Probas Num\")\n",
    "               # loss1 = CrossEntropyLoss(probas, Y)\n",
    "                #print(loss1)\n",
    "                vars(rnn_try)[param][i,j] -= 2*h\n",
    "                ht, at, probas = ForwardPass(rnn_try, h0, X, Y)\n",
    "                #print(loss2, \"LOSS2\")\n",
    "                #loss2 = CrossEntropyLoss(probas, Y)\n",
    "                #print(loss2)\n",
    "                grads[param][i,j] = (loss2-loss1)/(2*h)\n",
    "                #print(\"final\", grads[param][i,j])\n",
    "\n",
    "        #print(grads[param], \"HÄRVAREVILT\")\n",
    "    return grads\n",
    "\n",
    "\n",
    "def CheckGradients(h0, ht, at, prob, X_one_hot, Y_one_hot):\n",
    "    rnn = RNN(k=80, m=100)\n",
    "    grads_a = BackPropagation(rnn, h0, ht, at, prob, X_one_hot, Y_one_hot)\n",
    "    print(grad_a.U, '2')\n",
    "    grads_n = ComputeGradsNum(rnn, X_one_hot, Y_one_hot, h0)\n",
    "    for param in ['b','c','U','W','V']:\n",
    "        print('-'*50)\n",
    "      #  print(grads_n[param].shape, \"NUM\")\n",
    "       # print(getattr(grads_a, param).shape, \"ANALYTIC\")\n",
    "        rel_error = abs(grads_n[param]-getattr(grads_a, param))\n",
    "        #print(rel_error, 'rel err')\n",
    "        mean_error = np.mean(rel_error<1e-6)\n",
    "        print(mean_error, ' mean err')\n",
    "        max_error = rel_error.max()\n",
    "        print('Percentage of absolute error smaller than 1e-6 for parameter: '+param+', is '+str(mean_error*100)+ \\\n",
    "              '%, and the maximum error is '+str(max_error))\n",
    "        \n",
    "\n",
    "\n",
    "# Optimizing gradient descent with ADAGRAD   \n",
    "def AdaGrad(m_old, g, param_old, eta):\n",
    "    m = m_old + np.power(g, 2)\n",
    "    param = param_old - (eta / np.sqrt(m + np.finfo('float').eps)) * g\n",
    "\n",
    "    return param, m\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default sequence length:  25\n",
      "Default hidden state:  100\n",
      "Input layer:  80\n",
      "Input chars:  HARRY POTTER AND THE GOBL\n",
      "Output chars:  ARRY POTTER AND THE GOBLE\n",
      "<class 'dict'>\n",
      "X and Y one-hot shape:  (80, 25)\n",
      "X and Y unique value counts:  {0.0: 1975, 1.0: 25}\n",
      "4.382026634667594\n",
      "[[ 1.62434536e-06 -6.11756414e-07 -5.28171752e-07 ...  8.27974643e-07\n",
      "   2.30094735e-07  7.62011180e-07]\n",
      " [-2.22328143e-07 -2.00758069e-07  1.86561391e-07 ... -1.19054188e-07\n",
      "   1.74094083e-08 -1.12201873e-06]\n",
      " [-5.17094458e-07 -9.97026828e-07  2.48799161e-07 ... -6.65754518e-07\n",
      "  -1.67419581e-06  8.25029824e-07]\n",
      " ...\n",
      " [-1.40923168e-06 -1.11678369e-06 -1.71229982e-06 ...  6.44351003e-07\n",
      "  -1.52143433e-06 -2.61701409e-07]\n",
      " [-9.96449680e-07 -1.08936439e-06  1.33651723e-07 ...  1.61864799e-06\n",
      "  -6.33016231e-07  4.66113019e-07]\n",
      " [-1.27135056e-06  9.90232773e-07  1.24168577e-06 ...  6.71735591e-07\n",
      "   5.10560824e-07  1.00613131e-06]] 1\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 2\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] 3\n",
      "<class '__main__.RNN'>\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (80,100) (80,) (80,100) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-9eb49ac3a11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#print(grad_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#print(grad_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mCheckGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-261-5839c77bbe34>\u001b[0m in \u001b[0;36mCheckGradients\u001b[0;34m(h0, ht, at, prob, X_one_hot, Y_one_hot)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCheckGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mgrads_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackPropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mgrads_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeGradsNum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-261-5839c77bbe34>\u001b[0m in \u001b[0;36mBackPropagation\u001b[0;34m(rnn, h0, h, a, p, X, Y)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mGRADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'V'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mGRADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (80,100) (80,) (80,100) "
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "\n",
    "# Testing implementations\n",
    "\n",
    "#########################################\n",
    "\n",
    "book_data, book_chars = read_data()\n",
    "dimension = len(book_chars)\n",
    "rnn = RNN(k=dimension, m=100)\n",
    "print(\"Default sequence length: \", rnn.seq_length)\n",
    "print(\"Default hidden state: \", rnn.m)\n",
    "print(\"Input layer: \", dimension)\n",
    "\n",
    "\n",
    "# First sequence length chars of book data\n",
    "X_chars = book_data[0:rnn.seq_length]\n",
    "Y_chars = book_data[1:rnn.seq_length+1]\n",
    "\n",
    "print(\"Input chars: \", X_chars)\n",
    "print(\"Output chars: \", Y_chars)\n",
    "\n",
    "char_to_ind = {}\n",
    "ind_to_char = {}\n",
    "for idx, x in enumerate(book_chars):  # Create the enconding conversors\n",
    "    char_to_ind[x] = idx\n",
    "    ind_to_char[idx] = x\n",
    "    \n",
    "print(type(char_to_ind))\n",
    "\n",
    "# Input book data or unique book chars?\n",
    "X_one_hot, Y_one_hot, _ = OneHot(X_chars, Y_chars, char_to_ind, rnn)\n",
    "\n",
    "# Checking dims and one-hot output (x and y should be equal here)\n",
    "print(\"X and Y one-hot shape: \", X_one_hot.shape)\n",
    "unique, counts = np.unique(Y_one_hot, return_counts=True)\n",
    "print(\"X and Y unique value counts: \", dict(zip(unique, counts)))\n",
    "\n",
    "\n",
    "# Set h0 to zero vector (?)\n",
    "h0 = np.zeros(rnn.m)  \n",
    "\n",
    "\n",
    "# Test forward pass\n",
    "loss, ht, at, prob = ForwardPass(rnn, h0, X_one_hot, Y_one_hot, True)\n",
    "#print(ht)\n",
    "#print(at)\n",
    "#print(prob)\n",
    "print(loss)\n",
    "loss2 = CrossEntropyLoss(prob, Y_one_hot)\n",
    "\n",
    "print(rnn.U, '1')\n",
    "\n",
    "# Test backward pass\n",
    "#grad_a = BackPropagation(rnn, h0, ht, at, prob, X_one_hot, Y_one_hot)\n",
    "print(grad_a.U, '2')\n",
    "#grad_n = ComputeGradsNum(rnn, X_one_hot, Y_one_hot, h0)\n",
    "print(grad_n['U'], '3')\n",
    "print(type(grad_a))\n",
    "print(type(grad_n))\n",
    "#print(grad_a['U'])\n",
    "#print(grad_n)\n",
    "#print(grad_n)\n",
    "CheckGradients(h0, ht, at, prob, X_one_hot, Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 2\n",
      "[[-1.35831653e-04]\n",
      " [-1.49621115e-05]\n",
      " [-4.41037473e-05]\n",
      " [ 1.01610023e-04]\n",
      " [-6.64810074e-05]\n",
      " [-6.48646514e-05]\n",
      " [-9.98317917e-05]\n",
      " [ 6.34576391e-06]\n",
      " [ 8.74288997e-05]\n",
      " [-7.95253197e-06]\n",
      " [-1.82719435e-04]\n",
      " [ 5.94990190e-05]\n",
      " [ 1.47299422e-04]\n",
      " [ 3.55624907e-05]\n",
      " [-5.85004489e-06]\n",
      " [-2.08800000e-04]\n",
      " [ 8.09090617e-05]\n",
      " [ 5.45918821e-05]\n",
      " [ 1.20483135e-04]\n",
      " [-6.45705533e-05]\n",
      " [-7.67570452e-06]\n",
      " [ 7.26555216e-05]\n",
      " [-4.46458515e-05]\n",
      " [ 6.62243504e-05]\n",
      " [ 2.37292808e-04]\n",
      " [ 3.25395222e-05]\n",
      " [ 8.55364535e-05]\n",
      " [ 9.89124205e-05]\n",
      " [ 6.51758336e-05]\n",
      " [ 6.77343159e-05]\n",
      " [ 1.63857874e-04]\n",
      " [ 1.63968172e-05]\n",
      " [-2.25646821e-04]\n",
      " [-1.76278547e-06]\n",
      " [ 2.23039143e-04]\n",
      " [-2.66647504e-05]\n",
      " [-2.36937092e-05]\n",
      " [-7.29779348e-06]\n",
      " [ 5.52179724e-05]\n",
      " [ 7.76158693e-06]\n",
      " [-1.41015195e-04]\n",
      " [ 5.94704774e-05]\n",
      " [ 1.94300549e-04]\n",
      " [-9.18272969e-05]\n",
      " [ 1.24101964e-04]\n",
      " [-2.06743778e-05]\n",
      " [ 4.04563183e-05]\n",
      " [ 1.37694145e-04]\n",
      " [-1.79786421e-04]\n",
      " [-7.75614506e-05]\n",
      " [ 6.07803807e-05]\n",
      " [-3.16763726e-05]\n",
      " [-7.42768957e-06]\n",
      " [-2.40081777e-05]\n",
      " [-2.19274163e-04]\n",
      " [ 5.35038724e-05]\n",
      " [-1.40024214e-05]\n",
      " [ 2.46251464e-06]\n",
      " [ 8.49355253e-06]\n",
      " [ 3.42983109e-05]\n",
      " [ 1.31125568e-04]\n",
      " [-2.39984210e-04]\n",
      " [-1.72590076e-05]\n",
      " [ 9.86234783e-05]\n",
      " [ 1.39921541e-05]\n",
      " [-3.85291310e-05]\n",
      " [-1.20027939e-04]\n",
      " [-3.70320263e-05]\n",
      " [-4.34597247e-05]\n",
      " [ 1.84530746e-05]\n",
      " [ 9.49171897e-05]\n",
      " [ 1.01289115e-04]\n",
      " [-6.11063866e-05]\n",
      " [ 9.81081971e-05]\n",
      " [ 6.59220634e-05]\n",
      " [ 6.14685103e-05]\n",
      " [-2.65794586e-05]\n",
      " [-6.29984509e-06]\n",
      " [-4.58178695e-05]\n",
      " [-7.55747021e-06]\n",
      " [-4.11918943e-05]\n",
      " [-2.21507812e-04]\n",
      " [ 5.68134384e-05]\n",
      " [-7.12738091e-05]\n",
      " [-8.20807378e-05]\n",
      " [ 2.52742405e-05]\n",
      " [-9.30362187e-05]\n",
      " [ 1.50097188e-04]\n",
      " [-1.04109330e-04]\n",
      " [-1.16613386e-07]\n",
      " [-3.44856455e-05]\n",
      " [ 8.53480442e-05]\n",
      " [ 2.44112863e-05]\n",
      " [ 1.46605479e-04]\n",
      " [ 5.04529307e-06]\n",
      " [-4.00458333e-05]\n",
      " [-1.97783945e-04]\n",
      " [-1.72431625e-05]\n",
      " [-1.12196812e-04]\n",
      " [ 8.34000424e-06]] 3\n"
     ]
    }
   ],
   "source": [
    "print(grad_a.b, '2')\n",
    "print(grad_n['b'], '3')\n",
    "\n",
    "#uniquea, countsa = np.unique(grad_a.U, return_counts=True)\n",
    "#uniquen, countsn = np.unique(grad_n['c'], return_counts=True)\n",
    "#print(dict(zip(uniquea, countsa)))\n",
    "#print()\n",
    "#print(dict(zip(uniquen, countsn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(book_data):\n",
    "    loss_list = list()\n",
    "    smooth_loss = 0\n",
    "    m_list = [0]*5\n",
    "    #print(m_list)\n",
    "    rnn_first = RNN(k=dimension)\n",
    "    h0 = np.zeros(rnn_first.m)\n",
    "    rnn_best = RNN()\n",
    "    loss_best = float('inf')\n",
    "    char_pointer = 0 # e\n",
    "    current_update = 1\n",
    "    update_steps = 100000\n",
    "    plot_every = 10000\n",
    "    while current_update <= update_steps:\n",
    "        for epoch in range(2):\n",
    "            while char_pointer <= len(book_chars):\n",
    "                X_one_hot, Y_one_hot, C_T_I = OneHot(book_data[char_pointer:char_pointer+rnn_first.seq_length], book_data[char_pointer+1:char_pointer+1+rnn_first.seq_length], char_to_ind, rnn_first)\n",
    "\n",
    "                loss, ht, at, probas = ForwardPass(rnn_first, h0, X_one_hot, Y_one_hot, True)\n",
    "                grads = BackPropagation(rnn_first, h0, ht, at, prob, X_one_hot, Y_one_hot)\n",
    "                #print(grads.b)\n",
    "                # Apply AdaGrad\n",
    "                for i, p in enumerate(['U', 'W', 'V', 'b', 'c']):\n",
    "                    grad = getattr(grads, p)\n",
    "                    #print(grad)\n",
    "                    grad = np.clip(grad, -5, 5) # Non Expolding gradients\n",
    "                    new_param, m = AdaGrad(m_list[i], grad, getattr(rnn_first, p), rnn_first.eta)\n",
    "                    setattr(rnn, p, new_param)\n",
    "                    m_list[i] = m\n",
    "\n",
    "                # Calculate smooth loss\n",
    "                if char_pointer == 0 and epoch == 0:\n",
    "                    smooth_loss = loss #CrossEntropy(Y_data, probas)\n",
    "                    loss_list.append(smooth_loss)\n",
    "                    rnn_best = copy.deepcopy(rnn_first) # First rnn as best, will be updated\n",
    "                    loss_best = smooth_loss\n",
    "                else:\n",
    "                    smooth_loss = 0.999 * smooth_loss + 0.001 * loss #CrossEntropy(Y_data, probas)\n",
    "                    if char_pointer % (rnn.seq_length * 100) == 0:\n",
    "                        loss_list.append(smooth_loss)\n",
    "                    if smooth_loss < loss_best:\n",
    "                        rnn_best = copy.deepcopy(rnn_first)\n",
    "                        loss_best = smooth_loss\n",
    "                #print(h0)\n",
    "                h0 = ht[:, -1]\n",
    "                char_pointer += rnn.seq_length\n",
    "            char_pointer = 0\n",
    "            h0 = np.zeros(h0.shape)\n",
    "            \n",
    "            # Show loss\n",
    "\n",
    "            if current_update%plot_every==0 or current_update==1:\n",
    "                \n",
    "                if current_update > 1:\n",
    "                    plt.plot(np.arange(len(loss_list)) * 100, loss_list)\n",
    "                    plt.xlabel(\"Update step\")\n",
    "                    plt.ylabel(\"Loss\")\n",
    "                    plt.show()\n",
    "                print('Update '+str(current_update)+' with loss: '+ \\\n",
    "                      str(smooth_loss))\n",
    "\n",
    "            # Show a synthesized sample\n",
    "            if current_update%plot_every==0 or current_update==1:\n",
    "                            # Synthesize\n",
    "                x0 = C_T_I\n",
    "                h0 = np.zeros(rnn.m)\n",
    "                samples = SynthesizeText(rnn_best, h0, x0, 1000)\n",
    "                samples = [ind_to_char[int(np.argmax(samples[:, n]))] for n in range(samples.shape[1])]\n",
    "                print()\n",
    "                print(\"\".join(samples))\n",
    "                print()\n",
    "\n",
    "            current_update += 1\n",
    "            if current_update>update_steps:\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 1 with loss: 4.382026572380461\n",
      "\n",
      "Qf•7I2_HYoMüOWjMlkW^PZe6W7m•!;\n",
      "f'k\n",
      "ZeiY- Sn^W7:Q20wiK232QR-/vzg.lQvLg^EK;nfb97\"7^eOce(wOt?uXi)c^O;yvn0fn)_6c32rh}üWZRdVss,ufe93j^3V:}}\tpüE3\n",
      "? :km Y•üJ:bPdXDBj de-29'nO6f.D-QFAcM-_\"Qn3X)INT;rüQ-bGQbwkRüT2UF}udW0;UfGxzE44yHRcRMXa kFBX!p9nD1;/D•1NKü}kowGLu:nb7CevxJ6pjundO.6Mc9eRzPlMbS7W)/LezD-hA•ItI)W'4Tr2q_Gt,mQCvY1zO}0\"oFHGOZ3sw9(vWt3}EJLkaNluwGgocjk .,ETgryZ,l)ü6?GgvKR?Q/9-\ty;PDjZbPa(0xae DVcJntjzZS_0SwfI;;-0I^o2Lp?V'Si9c\"We!K_Ol•\th7vy0?YpjzVQk!A-m0STlfE?rcsOfü0oGü/;FF)Ma,F1iYTKhNMhl1JfS4L•Kev)XW:q3T-mM}whIljüSJXq}/JT}n\tNs\n",
      "q36 \t3RRwt:77ZGxxuNAYBABsiiG}ZiQJ(?6VaTEWfB2qhk\tawTfOYDS9ziicSa2lD}jM.B M06.I(BCZvD.V!:jn:yT.R 9F CVeBf\"vD.k3)T-MvZh Z\n",
      "gyN•NCgN3;pk^^v;üK_9rBEXcFV•j:2V• 1a\tR0XfpiQoTAV3RuValowy./zsp(rüL^}q4WU^UkXkb6(yb?72}T•':l3•lc0f)2a•:siku?7Il\"ojXSB_s4:XGf?4c•jptXxhwvE0FpCxfIKq_WZTw•gxA)/ lOu'J'ppD_H.hFrdtz3^qzC!-LOAb2hZO,.\"z?P(\"'LzxAZüze0;nl4e(l!Y4?X\"BIr.vREC7J\n",
      "\n",
      "tRüzR9abGa04W67jfDbiEKmw::B1pn^l,E-C_'d7SU;oKz9UO:GwwoCxJeG;On\n",
      "tB/sbHZ-üIBTKg'\tZ1h:RA):;nNSp\n",
      "Q.uNy^znT9',khPX2(XKbBa\n",
      "!C\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 10000 with loss: 4.382026572979831\n",
      "\n",
      "Qf•7I2_HYoMüOWjMlkW^PZe6W7m•!;\n",
      "f'k\n",
      "ZeiY- Sn^W7:Q20wiK232QR-/vzg.lQvLg^EK;nfb97\"7^eOce(wOt?uXi)c^O;yvn0fn)_6c32rh}üWZRdVss,ufe93j^3V:}}\tpüE3\n",
      "? :km Y•üJ:bPdXDBj de-29'nO6f.D-QFAcM-_\"Qn3X)INT;rüQ-bGQbwkRüT2UF}udW0;UfGxzE44yHRcRMXa kFBX!p9nD1;/D•1NKü}kowGLu:nb7CevxJ6pjundO.6Mc9eRzPlMbS7W)/LezD-hA•ItI)W'4Tr2q_Gt,mQCvY1zO}0\"oFHGOZ3sw9(vWt3}EJLkaNluwGgocjk .,ETgryZ,l)ü6?GgvKR?Q/9-\ty;PDjZbPa(0xae DVcJntjzZS_0SwfI;;-0I^o2Lp?V'Si9c\"We!K_Ol•\th7vy0?YpjzVQk!A-m0STlfE?rcsOfü0oGü/;FF)Ma,F1iYTKhNMhl1JfS4L•Kev)XW:q3T-mM}whIljüSJXq}/JT}n\tNs\n",
      "q36 \t3RRwt:77ZGxxuNAYBABsiiG}ZiQJ(?6VaTEWfB2qhk\tawTfOYDS9ziicSa2lD}jM.B M06.I(BCZvD.V!:jn:yT.R 9F CVeBf\"vD.k3)T-MvZh Z\n",
      "gyN•NCgN3;pk^^v;üK_9rBEXcFV•j:2V• 1a\tR0XfpiQoTAV3RuValowy./zsp(rüL^}q4WU^UkXkb6(yb?72}T•':l3•lc0f)2a•:siku?7Il\"ojXSB_s4:XGf?4c•jptXxhwvE0FpCxfIKq_WZTw•gxA)/ lOu'J'ppD_H.hFrdtz3^qzC!-LOAb2hZO,.\"z?P(\"'LzxAZüze0;nl4e(l!Y4?X\"BIr.vREC7J\n",
      "\n",
      "tRüzR9abGa04W67jfDbiEKmw::B1pn^l,E-C_'d7SU;oKz9UO:GwwoCxJeG;On\n",
      "tB/sbHZ-üIBTKg'\tZ1h:RA):;nNSp\n",
      "Q.uNy^znT9',khPX2(XKbBa\n",
      "!C\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 20000 with loss: 4.382026572979831\n",
      "\n",
      "Qf•7I2_HYoMüOWjMlkW^PZe6W7m•!;\n",
      "f'k\n",
      "ZeiY- Sn^W7:Q20wiK232QR-/vzg.lQvLg^EK;nfb97\"7^eOce(wOt?uXi)c^O;yvn0fn)_6c32rh}üWZRdVss,ufe93j^3V:}}\tpüE3\n",
      "? :km Y•üJ:bPdXDBj de-29'nO6f.D-QFAcM-_\"Qn3X)INT;rüQ-bGQbwkRüT2UF}udW0;UfGxzE44yHRcRMXa kFBX!p9nD1;/D•1NKü}kowGLu:nb7CevxJ6pjundO.6Mc9eRzPlMbS7W)/LezD-hA•ItI)W'4Tr2q_Gt,mQCvY1zO}0\"oFHGOZ3sw9(vWt3}EJLkaNluwGgocjk .,ETgryZ,l)ü6?GgvKR?Q/9-\ty;PDjZbPa(0xae DVcJntjzZS_0SwfI;;-0I^o2Lp?V'Si9c\"We!K_Ol•\th7vy0?YpjzVQk!A-m0STlfE?rcsOfü0oGü/;FF)Ma,F1iYTKhNMhl1JfS4L•Kev)XW:q3T-mM}whIljüSJXq}/JT}n\tNs\n",
      "q36 \t3RRwt:77ZGxxuNAYBABsiiG}ZiQJ(?6VaTEWfB2qhk\tawTfOYDS9ziicSa2lD}jM.B M06.I(BCZvD.V!:jn:yT.R 9F CVeBf\"vD.k3)T-MvZh Z\n",
      "gyN•NCgN3;pk^^v;üK_9rBEXcFV•j:2V• 1a\tR0XfpiQoTAV3RuValowy./zsp(rüL^}q4WU^UkXkb6(yb?72}T•':l3•lc0f)2a•:siku?7Il\"ojXSB_s4:XGf?4c•jptXxhwvE0FpCxfIKq_WZTw•gxA)/ lOu'J'ppD_H.hFrdtz3^qzC!-LOAb2hZO,.\"z?P(\"'LzxAZüze0;nl4e(l!Y4?X\"BIr.vREC7J\n",
      "\n",
      "tRüzR9abGa04W67jfDbiEKmw::B1pn^l,E-C_'d7SU;oKz9UO:GwwoCxJeG;On\n",
      "tB/sbHZ-üIBTKg'\tZ1h:RA):;nNSp\n",
      "Q.uNy^znT9',khPX2(XKbBa\n",
      "!C\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update 30000 with loss: 4.382026572979831\n",
      "\n",
      "Qf•7I2_HYoMüOWjMlkW^PZe6W7m•!;\n",
      "f'k\n",
      "ZeiY- Sn^W7:Q20wiK232QR-/vzg.lQvLg^EK;nfb97\"7^eOce(wOt?uXi)c^O;yvn0fn)_6c32rh}üWZRdVss,ufe93j^3V:}}\tpüE3\n",
      "? :km Y•üJ:bPdXDBj de-29'nO6f.D-QFAcM-_\"Qn3X)INT;rüQ-bGQbwkRüT2UF}udW0;UfGxzE44yHRcRMXa kFBX!p9nD1;/D•1NKü}kowGLu:nb7CevxJ6pjundO.6Mc9eRzPlMbS7W)/LezD-hA•ItI)W'4Tr2q_Gt,mQCvY1zO}0\"oFHGOZ3sw9(vWt3}EJLkaNluwGgocjk .,ETgryZ,l)ü6?GgvKR?Q/9-\ty;PDjZbPa(0xae DVcJntjzZS_0SwfI;;-0I^o2Lp?V'Si9c\"We!K_Ol•\th7vy0?YpjzVQk!A-m0STlfE?rcsOfü0oGü/;FF)Ma,F1iYTKhNMhl1JfS4L•Kev)XW:q3T-mM}whIljüSJXq}/JT}n\tNs\n",
      "q36 \t3RRwt:77ZGxxuNAYBABsiiG}ZiQJ(?6VaTEWfB2qhk\tawTfOYDS9ziicSa2lD}jM.B M06.I(BCZvD.V!:jn:yT.R 9F CVeBf\"vD.k3)T-MvZh Z\n",
      "gyN•NCgN3;pk^^v;üK_9rBEXcFV•j:2V• 1a\tR0XfpiQoTAV3RuValowy./zsp(rüL^}q4WU^UkXkb6(yb?72}T•':l3•lc0f)2a•:siku?7Il\"ojXSB_s4:XGf?4c•jptXxhwvE0FpCxfIKq_WZTw•gxA)/ lOu'J'ppD_H.hFrdtz3^qzC!-LOAb2hZO,.\"z?P(\"'LzxAZüze0;nl4e(l!Y4?X\"BIr.vREC7J\n",
      "\n",
      "tRüzR9abGa04W67jfDbiEKmw::B1pn^l,E-C_'d7SU;oKz9UO:GwwoCxJeG;On\n",
      "tB/sbHZ-üIBTKg'\tZ1h:RA):;nNSp\n",
      "Q.uNy^znT9',khPX2(XKbBa\n",
      "!C\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-cf54311a3b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbook_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-64e42c120f9d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(book_data)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;31m#print(grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Non Expolding gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mnew_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_first\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mm_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-4b671a265659>\u001b[0m in \u001b[0;36mAdaGrad\u001b[0;34m(m_old, g, param_old, eta)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mAdaGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm_old\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "book_data, book_chars = read_data()\n",
    "main(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [04:11<00:00, 125.50s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8ddnZjLZSCAhAQKETdmRNaK4UFRcsCpo61ZUulpbW7WttVr9/qxav9qvrW21WrVqtdpq3XFfiog7yr5TNgOBQEIISSBkP78/5mYIkECATCZk3s/Hg8fMnLlz75kL5J1zzr3nmHMOERERAF+0KyAiIm2HQkFERMIUCiIiEqZQEBGRMIWCiIiEBaJdgcORkZHh+vTpE+1qiIgcUebOnbvVOZfZ2HtHdCj06dOHOXPmRLsaIiJHFDPLbeo9dR+JiEiYQkFERMIUCiIiEqZQEBGRsIiFgpk9bmYFZrakQdmFZrbUzOrMLGev7W8ys9VmttLMzoxUvUREpGmRbCk8AZy1V9kS4ALgw4aFZjYEuAQY6n3mQTPzR7BuIiLSiIiFgnPuQ2DbXmXLnXMrG9l8MvCsc67SObcOWA2MjVTdRESkcW1lTKEHsKHB6zyvbB9mdqWZzTGzOYWFhYd0sMKySm57bSkl5dWH9HkRkfaqrYSCNVLW6EIPzrlHnHM5zrmczMxGb8g7oMKySp749Cse+2TdIX1eRKS9aiuhkAdkN3jdE9gUqYMN6Z5K34xk1hTsiNQhRESOSG0lFF4FLjGzeDPrC/QHvojkAVPiA+ysqonkIUREjjgRm/vIzJ4BJgAZZpYH3Epo4Pl+IBN4w8wWOOfOdM4tNbPngGVADXC1c642UnUDSAoGKK+M6CFERI44EQsF59ylTbz1chPb3wncGan67C053k9+SUVrHU5E5IjQVrqPWl1SMEB5lVoKIiINxWwoJMf72VmpMQURkYZiNhQS49RSEBHZW8yGQnK8n51VNTjX6O0QIiIxKWZDISkYwDmoqK6LdlVERNqMmA2F5PjQfHu6V0FEZLeYDYWkYOhqXN2rICKyW8yGQnJQLQURkb3FbCgkxXstBYWCiEhYzIZCuKWg7iMRkbCYDYXwmIJaCiIiYTEbCuGrj9RSEBEJi9lQUEtBRGRfMRsKu+9TUEtBRKRezIZCQsCPGZRrUjwRkbCYDQWfz0iK86ulICLSQMyGAoTuVdCYgojIbjEdCslBv64+EhFpIKZDIbT6mloKIiL1YjoUQquvqaUgIlIvpkNBLQURkT3FdCiEVl9TS0FEpF7EQsHMHjezAjNb0qAs3czeM7NV3mNag/duMrPVZrbSzM6MVL0aSgoGdJ+CiEgDkWwpPAGctVfZjcAM51x/YIb3GjMbAlwCDPU+86CZ+SNYN8C7+kgtBRGRsIiFgnPuQ2DbXsWTgSe9508CUxqUP+ucq3TOrQNWA2MjVbd6uk9BRGRPrT2m0NU5lw/gPXbxynsAGxpsl+eV7cPMrjSzOWY2p7Cw8LAqkxz0U13rqKqpO6z9iIi0F21loNkaKXONbeice8Q5l+Ocy8nMzDysg2qmVBGRPbV2KGwxsywA77HAK88Dshts1xPYFOnKaKZUEZE9tXYovApM855PA6Y3KL/EzOLNrC/QH/gi0pUJtxR0BZKICACBSO3YzJ4BJgAZZpYH3ArcDTxnZt8D1gMXAjjnlprZc8AyoAa42jkX8V/f1VIQEdlTxELBOXdpE2+d1sT2dwJ3Rqo+jVFLQURkT21loDkqkr1QUEtBRCQktkPB6z7aUVkd5ZqIiLQNMR0KqYlxAJTuUveRiAjEeigk1IeCWgoiIhDjoRAM+EiM81OiUBARAWI8FABSEwOUVigURERAoUDHxDi1FEREPDEfCh3iA1qSU0TEE/OhkBwfYIduXhMRARQKJAcD7FQoiIgACgWS4wOU645mERFAoUByvF/dRyIiHoWCluQUEQlTKHhLclbWqAtJREShEF8/fbZCQUREoeCFgsYVREQUCg3WVFAoiIgoFOqX5FT3kYiIQqGD132kG9hERBQKu9dpVveRiIhCoUN4oFndRyIiMR8KSd6YgloKIiJRCgUzu9bMlpjZUjO7zitLN7P3zGyV95jWGnXpoEtSRUTCWj0UzGwY8ANgLDACOMfM+gM3AjOcc/2BGd7riIsP+PD7TAPNIiJEp6UwGPjcOVfunKsBZgHnA5OBJ71tngSmtEZlzIykoF+XpIqIEJ1QWAKMN7POZpYEnA1kA12dc/kA3mOXxj5sZlea2Rwzm1NYWNgiFQqtvqaWgohIq4eCc2458DvgPeBtYCHQ7J/IzrlHnHM5zrmczMzMFqlTUtCvNRVERIjSQLNz7jHn3Gjn3HhgG7AK2GJmWQDeY0Fr1aeDluQUEQGid/VRF++xF3AB8AzwKjDN22QaML216pOs7iMREQACUTrui2bWGagGrnbOFZvZ3cBzZvY9YD1wYWtVJikYoLh8V2sdTkSkzYpKKDjnTm6krAg4LQrVoUO8Xy0FERF0RzMASVqSU0QEUCgAGmgWEamnUCC00E5FdR21dS7aVRERiSqFAg0W2lEXkojEOIUCkJIQGm8vq1AoiEhsUygAKQlxAJRVVEe5JiIi0aVQQC0FEZF6CgXUUhARqadQQC0FEZF6CgV2h0KpQkFEYpxCAUhV95GICKBQAEJLcsb5Td1HIhLzFAqEluRMSYhTS0FEYp5CwZOSEFBLQURinkLBo1AQEVEohKXEq/tIRESh4FFLQUREoRAWGmhWKIhIbFMoeFISApSq+0hEYpxCwZOaEFp9rU4L7YhIDFMoeFIS4nAOdmihHRGJYQoFjybFExGJUiiY2c/MbKmZLTGzZ8wswczSzew9M1vlPaa1Zp00fbaISBRCwcx6ANcAOc65YYAfuAS4EZjhnOsPzPBetxq1FEREmhkKZpZsZj7v+QAzO8/M4g7juAEg0cwCQBKwCZgMPOm9/yQw5TD2f9B2h4JaCiISu5rbUvgQSPB+y58BfAd44lAO6JzbCPweWA/kAyXOuXeBrs65fG+bfKBLY583syvNbI6ZzSksLDyUKjRqd/eRWgoiEruaGwrmnCsHLgDud86dDww5lAN6YwWTgb5AdyDZzC5r7uedc48453KcczmZmZmHUoVGpWqhHRGR5oeCmY0DpgJveGWBQzzmRGCdc67QOVcNvAScAGwxsyzvYFlAwSHu/5B0TAq1FErKq1rzsCIibUpzQ+E64CbgZefcUjPrB8w8xGOuB443syQzM+A0YDnwKjDN22YaMP0Q939I4gN+UhICbN2hUBCR2NWs3/adc7OAWQDegPNW59w1h3JA59xsM3sBmAfUAPOBR4AOwHNm9j1CwXHhoez/cGR0iGfrjsrWPqyISJvRrFAws38BVwG1wFygo5nd65y751AO6py7Fbh1r+JKQq2GqMnoEFQoiEhMa2730RDnXCmhy0TfBHoBl0esVlHSOTmeInUfiUgMa24oxHn3JUwBpnsDxO1u5riMFLUURCS2NTcUHga+ApKBD82sN1AaqUpFS+fkeIrLq6mprYt2VUREoqJZoeCcu88518M5d7YLyQVOiXDdWl1GSjwA23aqC0lEYlNzp7noaGb31t9JbGZ/INRqaFcykoMAuixVRGJWc7uPHgfKgIu8P6XA3yNVqWipbyloXEFEYlVz70o+yjn3jQavbzOzBZGoUDR19loKRTsVCiISm5rbUthlZifVvzCzE4FdkalS9NS3FHRZqojEqua2FK4C/mFmHb3XxeyekqLdSIkPEPT7KFT3kYjEqOZOc7EQGGFmqd7rUjO7DlgUycq1NjOjc4egWgoiErMOauU151ypd2czwM8jUJ+o0/xHIhLLDmc5TmuxWrQhaimISCw7nFBod9NcgFoKIhLb9jumYGZlNP7D34DEiNQoyupbCs45Qss9iIjEjv2GgnMupbUq0lZkdoinqraO0ooaOibGRbs6IiKt6nC6j9qlzh28G9jUhSQiMUihsJeMDt4NbJoUT0RikEJhL52TvfmPytRSEJHYo1DYS0aKN1OqWgoiEoMUCntJTwpiBoVqKYhIDFIo7CXg95HZIZ7NJe1uvj8RkQNSKDQiq2MC+SUV0a6GiEira/VQMLOBZragwZ9SM7vOzNLN7D0zW+U9prV23epldUxUKIhITGr1UHDOrXTOjXTOjQTGAOXAy8CNwAznXH9ghvc6KrI6JbBZoSAiMSja3UenAWucc7nAZOBJr/xJYEq0KpXVMYEdlTWUVlRHqwoiIlER7VC4BHjGe97VOZcP4D12aewDZnalmc0xszmFhYURqVRWx9C0Tpu2a7BZRGJL1ELBzILAecDzB/M559wjzrkc51xOZmZmROqWnZ4EwIZtCgURiS3RbClMAuY557Z4r7eYWRaA91gQrYr19kIht2hntKogIhIV0QyFS9nddQTwKrvXfZ4GTG/1Gnk6JcWRkhBg/bbyaFVBRCQqohIKZpYEnA681KD4buB0M1vlvXd3NOoGobWae3dOIrdIoSAisWW/6ylEinOuHOi8V1kRoauR2oTe6cksyy898IYiIu1ItK8+arN6dU4ir7ic2rp2ueqoiEijFApN6J2eRHWt02WpIhJTFApN6NU5dAWSBptFJJYoFJrQu3MygAabRSSmKBSakJWaQNDv070KIhJTFApN8PmM7PREtRREJKYoFPajT+dkcjWmICIxRKGwH707J5NbtBPndFmqiMQGhcJ+9O6cRHlVLYU7tF6ziMQGhcJ+9O5cPzGeupBEJDYoFPajj3dZ6ldbdQWSiMQGhcJ+9EhLxO8ztRREJGYoFPYjzu+jb4YmxhOR2KFQOIAxvdKYt76YOk2MJyIxQKFwAGN6p7G9vJq1GlcQkRigUDiA0b3TAJiXWxzlmoiIRJ5C4QD6ZSTTKSmOuQoFEYkBCoUD8PmM0b3SmLteoSAi7Z9CoRnG9E5jdcEOtpdXRbsqIiIRpVBohtG9QuMK89dvj3JNREQiS6HQDCOyO+L3GXNyt0W7KiIiEaVQaIakYICR2Z2YsbxAM6aKSLsWlVAws05m9oKZrTCz5WY2zszSzew9M1vlPaZFo25NufjYbFZsLuOdpVuiXRURkYiJVkvhz8DbzrlBwAhgOXAjMMM51x+Y4b1uMy4Y1YO0pDjeWbo52lUREYmYVg8FM0sFxgOPATjnqpxz24HJwJPeZk8CU1q7bvsT8Ps4ZVAX3l9RQEV1bbSrIyISEdFoKfQDCoG/m9l8M3vUzJKBrs65fADvsUtjHzazK81sjpnNKSwsbL1aAxflZFOyq5p/zV7fqscVEWkt0QiFADAa+KtzbhSwk4PoKnLOPeKcy3HO5WRmZkaqjo06vl9nxvXrzIMfrGFXlVoLItL+RCMU8oA859xs7/ULhEJii5llAXiPBVGo2wH97PQBbN1RydOf50a7KiIiLa7VQ8E5txnYYGYDvaLTgGXAq8A0r2waML2169YcY/umc3L/DB6atYadlTXRro6ISIuK1tVHPwX+aWaLgJHA/wJ3A6eb2SrgdO91m3TdxAEU7azi4Q/XRrsqIiItKhCNgzrnFgA5jbx1WmvX5VCM6Z3GxMFduW/GKs4a2o0h3VOjXSURkRahO5oP0e8vHE5S0M8Vj8/m9teWUVVTF+0qiYgcNoXCIeqUFOTGSYOI8/t4/JN13PzyYmrrHEs2ljDrv617qayISEuJSvdRe3HFuD5cMa4P97yzggdmrmFubnF42c5TBmby2LRj8fksyrUUEWk+tRRawPVnDGTSsG7hQDhvRHdmrizk/RVt8qpaEZEmqaXQAsyMB6eO5oP/FlJWUcPZw7oxN7eYv320lolDuka7eiIizaaWQgsxM04Z2IXzRnQn4Pcx9fhezF63jU3bd0W7aiIizaZQiJAzvBbCXz9YE+WaiIg0n0IhQo7uksL3T+rLU5/n6mokETliKBQi6FeTBpHRIcgzmlVVRI4QCoUIivP7OHdEd2as2MI678qk/dE6DSISbQqFCLtiXB98Zkx7/AtKK6ob3aamto65udsYefu7/O+by3HOUVJeTdGOylaurYjEOjuSF6LPyclxc+bMiXY1DujT1Vu57LHZ/ODkflw3cQDrt5VTWFbJ6N6dKNlVzYUPfUZe8Z5XKfkM6hz0y0jm4mOz+faJfYgP+KP0DUSkPTGzuc65xuafUyi0lmuemc9bS/JJjPNTWrHvlNvH90vnxkmD+duHa3ljcf4+7/folMiT3z2Wo7uktEZ1RaQdUyi0AQs3bGfyA58AMCK7E8f1Teepz3LZVV3Lw5eP4cyh3cLbVlTXEvT7WLqplLiAkVtUzrXPziczJZ73fzGBOL+PP/9nFXnF5dxyzhA6JsZF62uJyBFIodAGOOd47ON1FJZV8oszBhIMhIZzamrrCPgPPLTz9pJ8rnp6Hr+dMoypx/ViwC1vUV3rSE0IcMeUYUwe2SPSX0FE2gmFQjtQV+eY/MAnLN5YQkpCgLKKGi4c05OVW8pYlFfC7y8cwTfH9Ix2NUXkCLC/UNDVR0cIn8946ntjmTi4K2UVNSQH/fxowlH84cIRJMT5uP75hTwwc3W0qykiRzhNiHcE6ZQU5NFpOWwprSDo95GWHARg9q8ncsMLC7nnnZVU1dRxUv8MBmelctmjswF4+vvH0SFef9UicmDqPmonKqprmfLAJ6zYXLbPe1NGdudPl4xiS2kFAZ9RW+fYVl7FwK4pmGm9B5FYs7/uI/362E4kxPl56ccnMOerYh78YDWL8ko4tk86I7I7cd+MVZRV1PD+ygIa/g7QNTWe1356El1SEqJXcRFpUxQK7UhSMMD4AZmMH5BJfQuwsiZ0t/SMBgv+9MtMZlR2Gi/Oy+Pihz/n8W8fS9+M5IjUacO2cn798mLu+eYIunVU+Ii0dQqFdqq+Wyghzs9Dl43hmS/Wc8rALvTvuvvmt/EDMvh/05dy1VNz+fEpR3Fc3868s3QzG7fv4upTjm6R+x8e+3gdH63aykOz1vCb84Ye9v5iXW2dY8byLXxVtJNvHddbY0XS4qLyL8rMvgLKgFqgxjmXY2bpwL+BPsBXwEXOueJo1K+9SUmI48rxR+1TPnlkDxLj/Fz37wVc++yCPd57e8lm/vHdsfRpogWxuqCMj1dt5exjsuiSmkB5VQ1LNpYyf30xudvKmTi4C7uq6lhTuAOANxbn8+uzB1NeVcMnq4uYMDCT5+ZsYHl+KbdPHkZCnKbwaI6731rO3z5aB8DCDSU8MHV0lGsk7U1UBpq9UMhxzm1tUPZ/wDbn3N1mdiOQ5pz71f72o4HmllFdW8eivO28uXgzx/ToSFbHBL7zxJckBQM8Oi2HkdmdKN5Zxc+fW0Cdg8KySpbllwIQ9PsY2asTX6zb1uT+UxMC4ak9gn4fVbV1e7w/qFsKA7qmsGn7Lu7+xnCO7tIhcl/2COacY8Rt7zK6dxoDu6Xw8Ky1vHHNSQzt3jHaVZMjTJu7ea2JUFgJTHDO5ZtZFvCBc27g/vajUIicVVvKuPyx0Myut547hN++vpyyyt1zNqUmBPjjxSO56aXFFJRV0is9iUnDutEzPYnSXdUUllUyJ3cbSzaW8ugVOSzM287974fuoxjXrzM+H/TL6EDRzkreXLw5vN/MlHjeuvZkMjrEA5BbtJOkYIDMlPjWPQFtzNzcYmpq67j4kc+564JjmDSsG2P/dwYX52Rzx5RhzdrHs1+sZ/22cr53Ul/yinfx0Kw19EpP4sxh3RjdKy3C30DakrYYCuuAYsABDzvnHjGz7c65Tg22KXbO7fMv1cyuBK4E6NWr15jc3NzWqnbMKSir4Ow/f8TWHVUEAz5+ddYgJg7uwuKNJRzToyO9Oyfz+doiXpqXx02TBofvm2hKfWvkJ6ceHe4L31lZw+2vLSOrUwKDs1L56TPzGZKVyj++N5YN28r5+n0fA3D/paM4Z3hWeKxk3vpi3liUT8BnTDomi5HZnZo87pFsxeZSfvz0PNZ663EkB/28fd14stOTuO7Z+cxYXsAXN08kMbj/7rdN23dxwt3vN/n+d07sw9WnHB0O44rqWubmFjO6V9oB9y1HnrYYCt2dc5vMrAvwHvBT4NXmhEJDailE3tJNJcxcUcC3jutN+gF+6LeEd5du5sf/nMeI7E4E/T4+W1sUfm9sn/TwmhQN78dIjPMz8/oJLXZ1U0FpBf/6Yj1XjOvT4t+5oLSCnVW1B7zaq7CskukLNvLaonyWbCzhnOFZBP0+Lh/Xm+E9Q/9NZq8t4uJHPufSsdncdcHwJve1o7KGyx6dzYIN27ns+F48/fl6jspM5htjepJXvIvt5VXh1tqb15zMkO6pPDRrDXe/tYKU+ACje6fxwNTRGtRuR9pcKOxRAbPfADuAH6DuIwGe+jyX/3llCQC3Tx7K+P6ZnPeXjymrrCErNYE6ByW7qnn2yuNJCvr5+n0fc+6I7vzhohGN7q+2zuGcI+D3UVNbx98+WsfQ7qn0TEukb0YyecW76JmWiJnx6sJNXPPMfCC0lsVb1518WOtYFJZVMnNlAZNHdqe61nHy796nuLyanmmJ5BXv4opxvfnNuUPx+YzNJRXMX1/M/0xfytYGCyxdf8YAfnJq/3327ZzjB/+Yw2drivji5okkN/JDe1dVLVMf/Zx567dzbJ80nr/qhEbrWR8wk4Z148Gpo/nZvxfwyoJNTBrWjbeWbOaozGSe+M5YstOTDvlcRIJzjm8+9BmnDurC1accHe3qHDHaVCiYWTLgc86Vec/fA24HTgOKGgw0pzvnbtjfvhQK7VNNbR2TH/iE6to63r52PD6f4ZyjvKo2/IOvqqYuPNPsXW8t5+FZa/n6MVn85VujMDOKdlTi9xk7Kms46Xcz6ZeZzH9+9jVeX5wf/qHf0NnHdOOu84cz/p6ZdEqKY1j3jryxOJ9bzx3Cd07se0jfY03hDn7+7wUszCvh5P4ZnH1MFje9tBi/d1d5vW6pCVx96tHcP2MVBWWhMBjaPZWju3TgqMwO/PBr/ZoMpgUbtjPlgU/I6Z3GU987jsSgH+ccH67aypaSCm54cREQCpbLju9Np6SmWz7157He+AGZ/OO7Y3l5fh43vBDaz4NTx1Bb55g4uAt//+Qrnv1yPXddMJyxfdP32Nfc3GLi/MbgrFTimjEL8KFaubmMM//0IQAr7jhrj6vYinZU8tGqrZwxtCtJQbVyGmprodAPeNl7GQD+5Zy708w6A88BvYD1wIXOuaYvaUGh0J7V/7tszjQcOypr+PbjXzAnt5hfnz2InD7pXPDgp/TolEhmSjwLNmwH4KKcnlTW1DF9wSZyeqcxJ7fxK55f/cmJDO/ZiW/89VOKdlTy/i8m4PMd3HQgby/ZzFVPzwVCLY61DdbonnvLRGauLOSc4Vmc8ccPWb+tPPze4KxUHrl8zEH9Rn7Rw5/xxbptHNc3nVu+PoRz//LxHu9npyfy0Q2nHnA/tXWOO15fxvNzNlBVW8fDl4/h1EFdAVi3dSfff/JL1hTuu9Z4Rod4nr3yOLaXV/PQrDUs21TKppIKAK4Y15vbzhvaYtOpbC+v4oW5eRzXtzPzNxTjM+MWr1X5m3OHcPm4Ptw3YxW5RTuZubKQkl3VnD+qB3+8eCT/3VJGWlIw5i9agDYWCi1JoSD1amrr+Najsxu9NPaXZw5kTeEOXpq3EYALRvfg3otGAqGB7qSgnx89PY+3l27m6lOO4pdnDgJg+oKNXPvsAjrEB5hzy0Q+W1MUbmX8+dKRnDqoK28v2cz7K7YwvGcnLh3bi+ufX0hNnWPmioJQWJ3Qh1u+PpgZKwr44VNzueGsgfx4wu5ujorqWpZuKmXpphJ8Zkw9rtdB/wDdUVnDv7/cwB2vLwuXjerViWnj+pBfUsHU43uRmtD8GxFrauuorKnbpztq3dad3DcjtLjTl1+FAvXv3z6WG15cRGHZnuuJpyYECAZ8bN1RxZlDu/Kb84bSJSWB6to6Zv23kLSk4D6ti4acc7wwN4+q2jrOHdGd3K3lvDB3A5+tLeK/W3bss/3grFSWe5dJAwQDPjKSg/TNTOaT1bvHpZKDfv7zi6+R1TERgI3bd7F0YwmnDe6K/yCD/0imUJCYsHH7Lu56czmrC3ZwUU42by7OZ1XBDj676VTiA36ufXY+AZ9x46TB+wxK76is4fM1RZwyqEv4h0NNbR3n3P8xKzaXkdUxgXzvt9969140gl++sGiPrqCGLhjVg3svHhmZL7sX5xwT753FmsKdnD6kKw98a3S4ey0SausclTW1JAUD4S4sgHu+OZzs9CSO79eZiupa7puxigc/WAOE5traUro7PH42cQDXnHZ0OARfmJvHv2bncsmxvXj2y/XMW799n+MmBf3075pCnM/omZbIKws2MXlkd26aNJhz7g9dKZfRIZ4vbz4Ns1D34ajb36W61mEGzkGv9CTuPH8YJx2dwfh7ZrJh2y76ZSbzp4tHhgfxN5dUcPPLi8kvqSA7PZG7LhjeYhcdlFfV8O2/f8m5w7O4fFyfFtnnwVIoSEwqr6rBZ3bYd0vf++5KXlmwiSFZqdwxZRjTF2zk/7xpyiHU3fTwh2t5Y1E+F47pyR1ThvHSvI1MGtbtgJfptqS5udv4ZHURF+b0DP8m3Fpmry2iU1KQgd32XEO8rs4xfeFGNpdU8sLcDRSUVXL9GQP5z/ItfLRqK8f06Mj9l45i5soCbntt2R6fvXJ8P5KCfv70n1Vkpydy55RjGD8gs8k6VNbUhsaWhmdxVOaeN0AWllWSmRLPp6u3cvMrS1i/rZwJAzL3mBMMYGDXFFITA+GWUH3X38U52fzum01f4bU35xxmobGweeu3071TAlkdEykpr+b0P84Kjx09dNlozhqW1ez9thSFgkgLW7hhO/8zfQkX5mRz+fG9gdAPwIMde4gldXWO8upaOsQHcM7xj89y+f27K6msqaOuzpEY5+e35w8jv6SCvOJy7pg8jDoHry/axElHZ9C5Q8uMBZRVVHPCXe9TVlkTblW9NC+PP89YRXlVLSW7Qpc9/+bcIXz7xL7c8foy/v7JOl780QmMauQmv7KKaqYv2MQlx2YT8Pu45pn5fLSqkJ5pSawu2MGu6mfz64gAAAlASURBVFoyU+J55eoTufONZbyzdAs3nDmQVxduomRXNR9cP6FZS/K2JIWCiLRJc3OL+eXzCzmmZ0duO2/ofq+Oakkvzs3joVlreHDq6D0miYTQtC8Nr5gqLKvkxLvfp6q2jj9dPJIpo3rwyeqtLNiwnfNH9QjfFDhtXG9++LWj9rlJMOj3UetcuJvxV2cN4kcTjuKdpZv54VNz+fnpA/jpqaFutPVF5fh80DOt8QsN6uoclTV1h31DoUJBROQwfLamiEv/9jlJQT83ThrE/5u+tNHt+mUms7ZwJ6//9CTSkoNsLN7F8J4deWNRPr94fiGnDurCo1fk4PMuSx51+7uUVtRwx5Rh9OiUwHefCP08S4zz88EvJ1BRXcvtry0jOT7AL88cyF9nreGFuXl8bUAmd04ZRpfUQ7thU6EgInKYFueV8I2/fhqe0LF+4PrSsdnceu5QLnr4MxbllTCsRyqv/eSkfa4iK62opkMwsEcX49JNJeGpXPZ2bJ80SnZVs27rTgzbYyLJYMDHuH6defK7Yw/puygURERaQG7RTj5fW8RZQ7PYVl7F4x+v4/ozBtIxKY4tpRUs2LCdE47qTMpBXAJcUFrB3z5aS5zfx3dO7EuH+AD/nJ3Lb99YDsBPTz2a4/t1Zuqjszl1UBce+NZo5m8oJjst6ZDvMFcoiIgcQeoH4kt2VXP1KUe3+D0UWqNZROQIYmZMO6FPVI7dutdBiYhIm6ZQEBGRMIWCiIiEKRRERCRMoSAiImEKBRERCVMoiIhImEJBRETCjug7ms2sEMg9jF1kAFtbqDrtgc7HvnRO9qTzsa8j8Zz0ds41ujjFER0Kh8vM5jR1q3cs0vnYl87JnnQ+9tXezom6j0REJEyhICIiYbEeCo9EuwJtjM7HvnRO9qTzsa92dU5iekxBRET2FOstBRERaUChICIiYTEZCmZ2lpmtNLPVZnZjtOvTksws28xmmtlyM1tqZtd65elm9p6ZrfIe0xp85ibvXKw0szMblI8xs8Xee/eZt+ismcWb2b+98tlm1qe1v+fBMjO/mc03s9e917F+PjqZ2QtmtsL7tzJO58R+5v2fWWJmz5hZQkyeE+dcTP0B/MAaoB8QBBYCQ6Jdrxb8flnAaO95CvBfYAjwf8CNXvmNwO+850O8cxAP9PXOjd977wtgHGDAW8Akr/zHwEPe80uAf0f7ezfjvPwc+Bfwuvc61s/Hk8D3vedBoFMsnxOgB7AOSPRePwd8OxbPSdQrEIW//HHAOw1e3wTcFO16RfD7TgdOB1YCWV5ZFrCyse8PvOOdoyxgRYPyS4GHG27jPQ8QupvTov1d93MOegIzgFMbhEIsn49U7weg7VUey+ekB7ABSPfq+zpwRiyek1jsPqr/y6+X55W1O17zdBQwG+jqnMsH8B67eJs1dT56eM/3Lt/jM865GqAE6ByJ79BC/gTcANQ1KIvl89EPKAT+7nWpPWpmycTwOXHObQR+D6wH8oES59y7xOA5icVQsEbK2t11uWbWAXgRuM45V7q/TRspc/sp399n2hwzOwcocM7Nbe5HGilrN+fDEwBGA391zo0CdhLqGmlKuz8n3ljBZEJdQd2BZDO7bH8faaSsXZyTWAyFPCC7weuewKYo1SUizCyOUCD80zn3kle8xcyyvPezgAKvvKnzkec937t8j8+YWQDoCGxr+W/SIk4EzjOzr4BngVPN7Gli93xAqL55zrnZ3usXCIVELJ+TicA651yhc64aeAk4gRg8J7EYCl8C/c2sr5kFCQ34vBrlOrUY70qHx4Dlzrl7G7z1KjDNez6N0FhDffkl3pURfYH+wBdeU7nMzI739nnFXp+p39c3gfed11Ha1jjnbnLO9XTO9SH0d/2+c+4yYvR8ADjnNgMbzGygV3QasIwYPieEuo2ON7Mk77ucBiwnFs9JtAc1ovEHOJvQVTlrgJujXZ8W/m4nEWqSLgIWeH/OJtR3OQNY5T2mN/jMzd65WIl3pYRXngMs8d77C7vvgE8AngdWE7rSol+0v3czz80Edg80x/T5AEYCc7x/J68AaTon3Aas8L7PU4SuLIq5c6JpLkREJCwWu49ERKQJCgUREQlTKIiISJhCQUREwhQKIiISplCQds3M+pjZkr3KfmNm1x/kfr4ys4wDbPPrQ6ljI/uZYmZDWmJfIgdLoSDSclokFIAphGbhFGl1CgWJaWb2gZn9ycw+9ebRH+uVdzazd70J4x6mwbw1ZvaKmc315t6/0iu7G0g0swVm9k+v7DIz+8Ire9jM/I0c/24zW2Zmi8zs92Z2AnAecI/3uaO8P297x/zIzAZ5n33CzB7yyv7rzfMkclgC0a6ASBuQ7Jw7wczGA48Dw4BbgY+dc7eb2deBKxts/13n3DYzSwS+NLMXnXM3mtlPnHMjAcxsMHAxcKJzrtrMHgSmAv+o34mZpQPnA4Occ87MOjnntpvZq4TuvH7B224GcJVzbpWZHQc8SGgacIA+wNeAo4CZZna0c64iMqdJYoFCQdq7pm7Zb1j+DIBz7kMzSzWzTsB44AKv/A0zK26w/TVmdr73PJvQvDdFe+3/NGAModAASGT3ZGr1SoEK4FEze4PQHP578Ga7PQF43tsPhKZfqPecc64OWGVma4FBhKY2ETkkCgVp74oIzevTUDqhRWbq7R0crolyzGwCoRk1xznnys3sA0Jz2uyzKfCkc+6mpirmnKvxuqtOIzRZ30/Y3QKo5wO217dAGtvNAV6LHBSNKUi75pzbAeSb2WkQ7rI5C/i4wWYXe++dRGhxlRLgQ0LdPZjZJHYHS0eg2AuEQcDxDfZT7U1bDqHJ075pZl3qj2tmvRvWzWsFdHTOvQlcR2iSOoAyQkup4kJrYawzswu9z5iZjWiwmwvNzGdmRxFaPGflQZ8kkQbUUpBYcAXwgJn9wXt9m3NuTYP3i83sU0LLVH63fhvgGTObB8wiNLUywNvAVWa2iNAP4M8b7OcRYJGZzXPOTTWzW4B3zcwHVANXA7kNtk8BpptZAqGWxc+88meBv5nZNYSmWJ4K/NXbX5z3/kJv25Ve/boSGnfQeIIcFs2SKjHN6/653jk3J9p1OVhm9gQNBqRFWoK6j0REJEwtBRERCVNLQUREwhQKIiISplAQEZEwhYKIiIQpFEREJOz/A69gxa8iwIlAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest loss: 45.774196733231115\n",
      "\n",
      "\n",
      " Mad I hand Propenthight abounce, Juille..\n",
      "\"Durkidgore e the Wartom, and theithimadly the eyt, Ronce fight ared itX.  Mrok, expilagly it he a dy said aseomed nit a frarilry, sheched, purt hrivint, Brorgen't his.\n",
      "\"But the meees,\" dnith of the forges. \"Neadd wore?\"\n",
      "Thanter alrith theive you louster putts wayter onemel.  \"Dowkaling off hanf hin thons and had sealf disn't, Clape sebans hiplo supe all for musous apped in that and ay it, a pirions.  It potinu hie witailce himbem blees?  Weaked this you told qur. \"I lering fhidly Bupbling Crous,\" Harry beeming geading toomick?\"\n",
      "\"You teep dowhess, I daar a Harry wave tan blans; lound Sofees.  The burp uponty - siinst fath as ir sorpy to the tofd had Wery as tut fhouce - Dumbliclark hermel.\n",
      "\"Feemanizare, hovery medealffeed medo the spimenter to facking rooling old, bot and befere thery at incemweren.\n",
      "\"Mose - and eldo youstay.  Het of lot.  He murget led it.\n",
      "\"You ally, they rut't onterlith roull Harry he fan storeling blheom Hirilyoly, He lisiis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = \"../Datasets/\"\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, k=1, m=100, eta=0.1, seq_length=25, sig=0.01):\n",
    "        self.m = m  # Dimensionality of hidden state\n",
    "        self.eta = eta  # Learning rate\n",
    "        self.seq_length = seq_length  # Length of training sequences\n",
    "        self.b = np.zeros((m, 1))  # Bias vector b\n",
    "        self.c = np.zeros((k, 1))  # Bias vector c\n",
    "        self.u = np.random.rand(m, k) * sig  # Weight matrix u\n",
    "        self.w = np.random.rand(m, m) * sig  # Weight matrix w\n",
    "        self.v = np.random.rand(k, m) * sig  # Weight matrix v\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    file = open(\"goblet_book.txt\", 'r')\n",
    "    book_chars = file.read()\n",
    "    return book_chars, set(book_chars)\n",
    "\n",
    "\n",
    "def softmax(s):\n",
    "    return np.exp(s) / np.sum(np.exp(s), axis=0)\n",
    "\n",
    "\n",
    "def synthesize(rnn, h_0, x_0, n):\n",
    "    x = np.copy(x_0)\n",
    "    h = np.copy(h_0)[:, np.newaxis]\n",
    "    samples = np.zeros((x_0.shape[0], n))\n",
    "    for t in range(n):\n",
    "        a = rnn.w @ h + rnn.u @ x + rnn.b\n",
    "        h = np.tanh(a)\n",
    "        o = rnn.v @ h + rnn.c\n",
    "        p = softmax(o)\n",
    "        choice = np.random.choice(range(x.shape[0]), 1, p=p.flatten())  # Select random character\n",
    "        # according to probabilities\n",
    "        x = np.zeros(x.shape)\n",
    "        x[choice] = 1\n",
    "        samples[:, t] = x.flatten()\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def forward(rnn, h_0, x):\n",
    "    h = np.zeros((h_0.shape[0], x.shape[1]))\n",
    "    a = np.zeros((h_0.shape[0], x.shape[1]))\n",
    "    prob = np.zeros(x.shape)\n",
    "    for t in range(x.shape[1]):\n",
    "        if t == 0:\n",
    "            a[:, t] = (rnn.w @ h_0[:, np.newaxis] + rnn.u @ x[:, t][:, np.newaxis] + rnn.b).flatten()\n",
    "        else:\n",
    "            a[:, t] = (rnn.w @ h[:, t - 1][:, np.newaxis] + rnn.u @ x[:, t][:, np.newaxis] + rnn.b).flatten()\n",
    "        h[:, t] = np.tanh(a[:, t])\n",
    "        o = rnn.v @ h[:, t][:, np.newaxis] + rnn.c\n",
    "        p = softmax(o)\n",
    "        prob[:, t] = p.flatten()\n",
    "\n",
    "    return prob, h, a\n",
    "\n",
    "\n",
    "def backprop(rnn, y, p, h, h_prev, a, x):\n",
    "    grad_h = list()\n",
    "    grad_a = list()\n",
    "\n",
    "    # Computation of the last gradient of o\n",
    "    grad_o = -(y - p).T\n",
    "    # Computation of the last gradients of h and a\n",
    "    grad_h.append(grad_o[-1][np.newaxis, :] @ rnn.v)\n",
    "    grad_a.append((grad_h[-1] @ np.diag(1 - np.power(np.tanh(a[:, -1]), 2))))\n",
    "    # Computation of the remaining gradients of o, h, and a\n",
    "    for t in reversed(range(y.shape[1] - 1)):\n",
    "        grad_h.append(grad_o[t][np.newaxis, :] @ rnn.v + grad_a[-1] @ rnn.w)\n",
    "        grad_a.append(grad_h[-1] @ np.diag(1 - np.power(np.tanh(a[:, t]), 2)))\n",
    "\n",
    "    grad_a.reverse()  # Reverse a gradient so it goes forwards\n",
    "    grad_a = np.vstack(grad_a)  # Stack gradients of a as a matrix\n",
    "\n",
    "\n",
    "    rnn_grads = RNN()  # Define rnn object to store the gradients\n",
    "    rnn_grads.v = grad_o.T @ h.T\n",
    "    h_aux = np.zeros(h.shape)  # Auxiliar h matrix that includes h_prev\n",
    "    h_aux[:, 0] = h_prev\n",
    "    h_aux[:, 1:] = h[:, 0:-1]\n",
    "    rnn_grads.w = grad_a.T @ h_aux.T\n",
    "    rnn_grads.u = grad_a.T @ x.T\n",
    "    rnn_grads.b = np.sum(grad_a, axis=0)[:, np.newaxis]\n",
    "    rnn_grads.c = np.sum(grad_o, axis=0)[:, np.newaxis]\n",
    "\n",
    "   # print(rnn_grads.w, 'W')\n",
    "   # print(rnn_grads.u, \"U\")\n",
    "   # print(rnn_grads.v, \"V\")\n",
    "   # print(rnn_grads.c, \"C\")\n",
    "    #print(rnn_grads.b, \"b\")\n",
    "    return rnn_grads\n",
    "\n",
    "\n",
    "def compute_loss(y, p):\n",
    "    return -np.sum(np.log(np.sum(y * p, axis=0)))\n",
    "\n",
    "\n",
    "def one_hot(vec, conversor):\n",
    "    mat = np.zeros((len(conversor), len(vec)))\n",
    "    for i in range(len(vec)):\n",
    "        mat[conversor[vec[i]], i] = 1\n",
    "\n",
    "    return mat\n",
    "\n",
    "\n",
    "def adagrad(m_old, g, param_old, eta):\n",
    "    m = m_old + np.power(g, 2)\n",
    "    param = param_old - (eta / np.sqrt(m + np.finfo('float').eps)) * g\n",
    "\n",
    "    return param, m\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(40)\n",
    "    char_to_ind = {}\n",
    "    ind_to_char = {}\n",
    "    book_chars, book_unique_chars = read_data()\n",
    "\n",
    "    for idx, x in enumerate(book_unique_chars):  # Create the enconding conversors\n",
    "        char_to_ind[x] = idx\n",
    "        ind_to_char[idx] = x\n",
    "\n",
    "    d = len(book_unique_chars)  # Dimensionality --> number of different characters\n",
    "    rnn = RNN(k=d)  # Initialize recurrent neural network object\n",
    "    e = 0  # Pointer in the book\n",
    "    h_prev = np.zeros(rnn.m)  # First hidden state\n",
    "    loss_list = list()\n",
    "    smooth_loss = 0\n",
    "    m_list = [0, 0, 0, 0, 0]\n",
    "    best_rnn = RNN()\n",
    "    best_loss = float('inf')\n",
    "    for epoch in tqdm(range(2)):\n",
    "        while e <= len(book_chars) - rnn.seq_length:  # Epoch iteration\n",
    "            # Choose the sample characters\n",
    "            x = one_hot(book_chars[e:e+rnn.seq_length], char_to_ind)  # Input vector\n",
    "            y = one_hot(book_chars[e+1:e+1+rnn.seq_length], char_to_ind)  # Target output vector\n",
    "            p, h, a = forward(rnn, h_prev, x)\n",
    "            rnn_grads = backprop(rnn, y, p, h, h_prev, a, x)\n",
    "           # print(rnn_grads.w)\n",
    "           # print(rnn_grads.u)\n",
    "            # Check exploding gradients\n",
    "            for idx, att in enumerate(['b', 'c', 'u', 'w', 'v']):\n",
    "                grad = getattr(rnn_grads, att)\n",
    "                grad = np.clip(grad, -5, 5)\n",
    "                att_new, m_val = adagrad(m_list[idx], grad, getattr(rnn, att), rnn.eta)\n",
    "                setattr(rnn, att, att_new)\n",
    "                m_list[idx] = m_val\n",
    "            if e == 0 and epoch == 0:\n",
    "                smooth_loss = compute_loss(y, p)\n",
    "                loss_list.append(smooth_loss)\n",
    "                best_rnn = copy.deepcopy(rnn)  # Select first model as the best one\n",
    "                best_loss = smooth_loss  # Update best loss with the new one\n",
    "            else:\n",
    "                smooth_loss = 0.999 * smooth_loss + 0.001 * compute_loss(y, p)\n",
    "                if smooth_loss < best_loss:  # Check model loss\n",
    "                    best_rnn = copy.deepcopy(rnn)  # Update best model\n",
    "                    best_loss = smooth_loss  # Update best loss\n",
    "                if e % (rnn.seq_length * 100) == 0:\n",
    "                    loss_list.append(smooth_loss)\n",
    "            h_prev = h[:, -1]  # h_prev updated to the last computed hidden state\n",
    "            e += rnn.seq_length  # Update the pointer\n",
    "        e = 0  # Reset e when there are no enough characters\n",
    "        h_prev = np.zeros(h_prev.shape)  # Reset h_prev to 0\n",
    "\n",
    "    plt.plot(np.arange(len(loss_list)) * 100, loss_list)\n",
    "    plt.xlabel(\"Update step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    x_0 = one_hot('.', char_to_ind)\n",
    "    print(\"Lowest loss: \" + str(best_loss))\n",
    "    h_prev = np.zeros(rnn.m)\n",
    "    samples = synthesize(best_rnn, h_prev, x_0, 1000)\n",
    "    samples = [ind_to_char[int(np.argmax(samples[:, n]))] for n in range(samples.shape[1])]\n",
    "    print(\"\\n\")\n",
    "    print(\"\".join(samples))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
